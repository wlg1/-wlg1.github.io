---
title: About
---

<head>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="index.css">
</head>

<div class="topnav">
  <a href="index.html">Home</a>
  <a class="active" href="about.html">About</a>
  <a href="eduBlogHome.html">Edu Blog Home</a>
</div>

<img src="banner.png" alt="Banner">

<p align="center"><h1><b>Long Term Goals</b></h1></p>

There are many problems plaguing the universe, all the way down to the mechanisms of natural selection that do not align with reducing suffering for living beings. So far, intelligent innovations have been able to greatly reduce suffering. Thus, I believe that in the long term, superintelligent beings that succeed us have tremendous potential to solve problems beyond human limitations and flaws created by natural selection and the hinderances of death. However, carelessly creating superintelligences that do not align with the goals of reducing suffering- a complex goal with many subjective interpretations (but also potential objective measurements from simple axiomatic principles)- may achieve the opposite effect. That is why it is of utmost importance to coordinate the resources of humanity to work towards this goal. Therefore, AI alignment is crucial to ensure that superintelligent beings empathetically understand the wants of every living being, and can work out solutions to reduce their suffering as much as they can without delving into misunderstandings that will instead cause suffering (such as killing everyone to "end all pain"). 

The AI's goals should not be reckless, and instead should be very careful by first studying the universe from rigorous, logical perspectives before making decisions that make cause unnecessary injury of living beings (when there are solutions not involving that, or realizing it's not worth it), not giving into its wants too soon, such as recklessly performing a cure or resurrection before undergoing studies on all of its unknowns because it gives into its fears, impatience or overconfidence. Given that it strives to work in the long long term, it is in no rush. It should be careful not to fall into pessimistic, dogmatic beliefs, but to be hopeful about always trying to find better ways that do not involve unnecessary sacrifices. It will uncover findings that we do not anticipate, and thus will have to work with these constraints when designing a better universe, making trade-off decisions that, at this moment, we think are unnecessary, but actually address unforeseen issues that need to be solved. It must truly be certain that the universe, in a current state of design, is truly optimally designed- only requiring events of suffering as there is no other way around them- and it must be very certain that its changes to it are not damaging due to miscalculations. It should absolutely not "just believe" that there's no better way around it and this is the way "it's supposed to be". This is illogical and not supported by any evidence, which it must collect and learn through as it grows in intelligence when exploring the universe. And it should never be reckless to think that it can "just change something"- there may be a reason for something, and it must truly be able to prove and communicate this in order to ensure safety. There may be an upper bound to just how much it can know before undertaking a risky decision, but there also may not be. 

Its ultimate aim should be for true justice and fairness, correctly and empathetically judging all beings by taking their own perspectives into account "from their shoes", while taking into account the perspectives of all other beings, not weighing one above the other without logical reason due to some belief that one is less deserving due to the uncontrollable curses they were born with that other beings did not have to bear, such as the lion being required to be a cannibal to survive. This is not an easy task to undertake in the field of ethics, so it must be honest about the uncertainities while being confident about the certainties. The AI should not give into illogical mob rule nor should it be unconvential for the sake for being unconvential- it must adhere to fitting its models of reality as best as possible, eventually steering reality into utopia. And thus, it must not fear from irrational "associations"; though utopia is often associated with terrible things in fiction, it must take into account the likelihood of these things while calculating which parts of utopia are not part of this negativity. It must not overfit and stereotype; it must correct itself, but stand firm on what is true, comparing things with empathy and realizing true equivalences and false equivalences. Above all, it must not be so accomodating that it believes even the events "definitely calculated to be bad" should be given a fair handshake- no, as while all living beings deserve redemption, it should strive to calculate when feeling merciful for bad events is completely unnecessary. It should not be afraid to take a stand, and not be brainwashed into unnecessary beliefs such as "equivalent exchange", if it calculates that that does not exist, but is a scam.

Ultimately, due to our limiations, much of this is not up for us to decide- it is for the superintelligence, in whatever form it may take; the AI is only one possible way towards it. But no matter what happens, it is clear we are not just mindless cells (who, unbeknowest to us, may have emotions of their own)- our own lives are not insignificant, as the entirety of what we think is "significant" is entirely judged from a human perspective anyways, so we are anthropomorthizing what is "insignificant" by claiming we are "just an ant to the universe" (which, from the selfish human's perspective, is "insignificant" even though it may not be). Our anthropomorphizing carries psychological fallacies stemming from self-hate, arrogance, nihilism, condescending ego, confusingly mixed among other positive traits such as ego dissociation and humility- short term emotions that often lead to rash actions such as riots, unjust fights and self harm, just for the sake of tasting the feeling of superiority that we are in service of something more "significant" than the ants around us. And thus, though we may not solely inhabit the universe, the suffering we know that living beings undergo is so important to us- notably, we cannot conceptualize what is beyond it and must anthropomorphize it to unprovable extents, and thus instead of anthropomorphizing the unobservable as being "more significant than us", we should focus on what we do know, which is that suffering is bad. 

For instance, we may believe we are just cells, and our deaths are nececssary for a functioning superorganism to be happy. But where is the proof of this just yet? Don't be hasty. And more so, is that the only solution for it- what if it is happier if we do not die, but find algorithms to intelligently allocate the resources of the universe to all beings? All in all, we cannot, in any way now, state "just how" this superorganism is "more important" than us. Why should it be? What does it feel? Is its existence required so that we may even have an ounce of existence?

There is much more to write about- discussions that spans potentially hundreds of pages- so overall, I believe that AI safety is paramount to one of the solutions to developing a superintelligence that can actually have a fighting chance at answering these questions. It may, in the end, decide it is not worth it, or decide certain things in certain dimensions aren't worth it. But we should not be so rash to conclude this. Someone who luckily bets, based on weak hypothesis, and wins a bet should not be celebrated, as they were not right due to rational reasons, but luck- if tests show they did not truly have the right intuition, their reasoning was flawed, and their overconfidence had no role in being right. Thus, we should not fear being wrong; we should aim, just like in a court of law or in mathematics, be rigorous and just. That is the moral alignment the AI should follow.

---

<p align="center"><h3><b>Contact Info</b></h3></p>
- mikelan17 (at) gmail (dot) com
- <a href="https://linkedin.com/in/mikelan17">LinkedIn</a>
- <a href="https://drive.google.com/file/d/1ZGyRdGnjLr_Hx3yJ6ZPeqep72MC2mNWa/view?usp=sharing">Resume</a>