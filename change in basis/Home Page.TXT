(Aside from the home page, there are many entrances called 'doors' to this website, which you click on based on what interests you. Someone interested in clear cut explanations of unfamiliar terms that get to the point may find a link using one door; another person interested in "entertainment" may use another door)

When studying new improvements to neural networks, many people run into this problem:
1) The math terminology is unfamiliar. When one looks up the terms, the articles describing them use even more unfamiliar terms, and because they're not efficiently tailored towards the paper one is reading, there's so much extra stuff in them that it's very time consuming to learn.

Eg) What's eigenvector decomposition? How can I learn this as fast as possible?
Don't use example from actual paper

This website solves this problem:
1) It explains all the required prerequisites needed to understand the terminology from the bottom up*, so one does not have to go through a time consuming scavenger hunt to understand all of them; they're all neatly collected in one place. The website cuts out all the extra information that's not needed to understand how this term is used for this neural network paper. 
*assuming only that a reader has a basic understanding of X, or has watched these videos []. Links are provided to them.

There is a second problem that many people run into:
2) Concepts are introduced such that one doesn't know why they're important. What's their purpose? How is it connected to improving a neural network?

[image caption: All of a sudden we're spending an hour talking about X. ]

This website also solves this problem:
2) All explanations get to the point. They always start off by stating the issue that this concept will solve, and how that issue will improve a neural network. Then, they go further by saying how generalizing this solution can solve similar problems, thus showing the long term usefullness of the concept.