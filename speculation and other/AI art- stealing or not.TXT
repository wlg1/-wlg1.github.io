The definition of stealing is very subjective and depends on your definition of how other people's art is used. If someone wants to make an opinion but is not sure how these tools work, I'd suggest watching videos on how neural networks work such as this one that don't require a lot of prerequisites:
https://youtu.be/aircAruvnKk

After watching this, one understands the concept of artificial neurons. In a simplified explanation, the way the art is created is that each pixel is an output node that is a sum of other neurons. When the Neural Network learns from someone else's art, it has no way of copying it directly. It can't store all of its pixels into its neurons. Instead, it adjusts each of its neurons based on the image it learns from. What does this mean? Let's make an analogy to how a human wants to learn to draw what a bear is, because how the human learns is what the Neural network was based on. The human looks at a bunch of images of bears, and she'll first draw something with four legs and a head, but it's a crude drawing. She looks at more bear images and realizes the body needs to be bigger, so her next drawing is more like a bear. She looks at even more drawings again, and realizes she forgot ears. Her next work is even more like a bear as it has ears now. After analyzing and trying more drawings thousands of times, she has a bear drawing. In this analogy, each adjustment the human learns is like an adjustment of a neuron. Ignoring all the complicated neural network architecture and training of models such as clip and diffusion, a neuron merely has "weights" that, much like how a human "weighs" how big of a circle her hand must draw, adjust how it outputs its result. So you can think of weights like how we "weigh" each decision. These neurons are acting much like how a human manually adjusts each line. In fact, in models called CNNs, there is evidence that some neuron weights act as "edge detectors" which actually do adjust each line of a drawing. All of this is a simplified explanation so if you actually understand the intricate process of each model you'd find this explanation hand waves some details but this is accurate to describing the high level idea in an accessible way.

Now is this exactly how the human mind works? No, it is an analogy. But on both sides of this analogy, the human and neural network AI do not have an entire copy of an artist's drawing to be pasted. They are, using micro adjustments, constructing a bear pixel by pixel, line by line, paw to paw, making small adjustments relative to the entire picture as they go, merely using the previous artworks as to how they already fine tuned these weighted "feelings" of adjustments. Knowing this will help someone have better confidence in knowing how AI makes art, and to make decisions on whether it's stealing or not. 

This is the fact on how AI generated art.  As for my opinion on whether AI artists are artists or not, I think that is very much up for debate. But another fact I believe is that the work that artists put into learn and manually create each part of their drawing from their own creative mind is much more than what prompt users do. The human artist, much like the AI, goes through thousands of trial and error to learn. As anyone who has learned to make art knows, to disregard that is disrespectful to the act of learning to draw itself. But that is not to say that prompt generation is not a craft itself; that is a skill that requires learning, but learning to use it to make a detailed bear is nowhere near the thousands of hours required to learn to paint a bear of the same quality that an AI generates. As for my interpretation of whether it's stealing or not, no, it's not stealing, going by the reasoning of the analogy I made above. But do the artists give permission for their art to be used? If an art piece is put on the internet, it is implicitly permitted for any human to use that art to learn how to draw, though to NOT trace and plagiarize without credit. The AI is learning from it in a very similar way, like a human, as they're not tracing over exact pieces. Adjusting each weight to fit an exact piece can be very hard, and (perhaps) probabilistically very unlikely to be outputted, given the huge number of possible outputs an AI can make. But again, this is an implicit assumption; the artist allows any HUMAN to learn from it, not an AI. So perhaps in the future there can be permissions, such as when data scraping, that an artist puts which forbids their art to be used in training data (legally this can be hard to enforce though). Or perhaps each model should have its training data made transparent (again, just because someone claims that's the training data, still makes it hard to prove it didn't use certain pieces, but it's possible future research can create tools to check for this)

<<<
It is POSSIBLE for an AI to recreate an exact drawing if that's the only drawing in its dataset that it's overfitting to. But this is much like if an artist spent hours training to re-create one exact piece of artwork. For the AI to adjust its weights to accomodate millions of art pieces means it's unlikely to output an exact drawing.

The AI looks at many drawings as one drawing may not capture everything about a bear; it also needs to see bears at different angles, at different positions, with different expressions, etc.