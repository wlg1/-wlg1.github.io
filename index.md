---
title: About This Website
---
**WORKING TITLE**

**[ch1.1](ch1.1.md)**

<a href="ch1.1.html">CHAPTER 1.1</a>

**[ch1.2](ch1.2.md)**

<a href="ch1.2.html">CHAPTER 1.2</a>

When studying new improvements to neural networks, many people run into the following problem:

The terminology, such as the mathematical concepts, is unfamiliar. When one looks up the terms, the articles describing them use even more unfamiliar terms, and because they're not efficiently tailored towards the paper one is reading, there's so much extra stuff in them that it's very time consuming to learn. Concepts are introduced such that one doesn't know why they're important. What's their purpose? How is it connected to improving a neural network?

Eg) What's eigenvector decomposition? How can I learn this as fast as possible?
Don't use example from actual paper

[image caption: All of a sudden we're spending an hour talking about X. ]

This website solves this problem:
It explains all the required prerequisites needed to understand the terminology from the bottom up, so one does not have to go through a time consuming scavenger hunt to understand all of them; they're all neatly collected in one place. The website cuts out all the extra information that's not needed to understand how this term is used for this neural network paper. 
assuming only that a reader has a basic understanding of X, or has watched these videos []. Links are provided to them.

[give an example of issue- reasoning- soln - generalization, that concisely explains all after prereqs]

All explanations get to the point. They always start off by stating the issue that this concept will solve, and how that issue will improve a neural network. Then, they go further by saying how generalizing this solution can solve similar problems, thus showing the long term usefullness of the concept.

<!---
For localhost testing:

<a href="ch1.1.html">CHAPTER 1</a>
-->