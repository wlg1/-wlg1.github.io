"music to picture neural network"

https://personads.me/projects/synvae/
Similar looking images should therefore translate into similar sounding music.

https://arxiv.org/pdf/1909.01218.pdf
An image is first encoded into a latent vector zv by the VisVAE encoder, before being decoded into music by the MusicVAE decoder. During training, the music is subsequently re-encoded into za by the MusicVAE encoder and reconstructed into the output image by the VisVAE decoder

<<<
https://magenta.tensorflow.org/music-vae

We can also use the structure of the latent space to perform semantically meaningful transformations, such as with “latent constraints” or “attribute vector arithmetic”.
By averaging the latent vectors corresponding to a collection of datapoints which share a given quality (for example, sketches of cat faces), we obtain the attribute vector for that attribute (the “cat face vector”)
https://colab.research.google.com/notebooks/latent_constraints/latentconstraints.ipynb
https://arxiv.org/abs/1711.05772

A key component of an AE is the bottleneck introduced by making the vector have fewer dimensions than the data itself, which forces the model to learn a compression scheme. In the process, the autoencoder ideally distills the qualities that are common throughout the dataset

<<<
https://distill.pub/2017/aia/
. It’s remarkable that just 4040 numbers can capture the apparent complexity in a glyph, which originally required 4,0964,096 variables.
Such heuristics can be used to create fonts with properties which would otherwise be unlikely to occur to users. Thus, the tool expands ordinary people’s ability to explore the space of meaningful fonts.
In this it resembles a program such as Photoshop or a spreadsheet or 3D graphics programs
pix2pix (not generative; doesn't manip latent space directly?)

https://magenta.tensorflow.org/midi-me

https://medium.com/@torinblankensmith/melody-mixer-using-deeplearn-js-to-mix-melodies-in-the-browser-8ad5b42b4d0b

2022: Flat latent manifolds for music improvisation between human and machine
https://arxiv.org/abs/2202.12243

https://scholar.google.com/citations?user=9ziPoxAAAAAJ&hl=en

<<<
https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w49/Qiu_Image_Generation_Associated_CVPR_2018_paper.pdf
Image generation associated with music data

https://www.researchgate.net/publication/346450506_Painting_from_Music_using_Neural_Visual_Style_Transfer

<<<<<<<<
https://www.gwern.net/docs/www/old.reddit.com/aae34108a9eb44222d7b21a3fab43dc1c4285bb7.html
[P] Using StyleGAN to make a music visualizer

https://www.youtube.com/watch?v=rqEaOL-TzDg&ab_channel=Anjunadeep