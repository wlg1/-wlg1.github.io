CODING TO DO:

MACRO GOAL: 

V 1. put pdf from local into pinecone
    test_pinecon_gpt.py
        index = Pinecone.from_documents(docs, embeddings, index_name)
V 2. call gpt using langchain on pdfs from pinecone
    test_pinecon_gpt.py

V 3. retrieve pdfs from arxiv and put into pinecone
    arxiv_to_pinecone.py
    multi_arxiv_to_pinecone.py

    
<<<<<<<<

. search for semantic meaning in pdfs and retrieve approx location. (suggested results given query)
    chatgpt: Now given a query, search arxiv for the first 3 pdf results and download them

. compare pdfs, then write suggested summary w/ refs
.compare pdfs, then write suggested table w/ refs

use multiple queries to get separate papers, then combine them
note that you aren't going to get exact papers anyways; your search term will find diff papers
to get diff papers, upon embedding, use diff 'paper ids' (metadata)


use ROME and memit as a starting point- generalize them, and connect to ai assistant

<<<
don't put kaggle api key on github

<<<<<<<<<<<<<<<<<<<<<<<<
INVESTIGATION TO DO:

1. learn limitation of autogpt and agentgpt
    D:\Documents\_rsch\applications\AI document search\existing tools


<<<<<<<<
learn auto gpt features, how it was built