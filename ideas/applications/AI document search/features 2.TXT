1. Read and compare papers. Simplify, summarize, find. Make tables from them.
Why org this way? Format into prob solns. Analogies.
2. Make expms from papers. Variations. Log. Run and Label as neg. Find itself any corrections to double check. Store description of expm results in vector db and search. Use Metadata too 
3. Make latex from eqns and expms. Write paper

Deploy as web app GUI for anyone to try on a model

reflexion (multi prompt) is key. autuonomous is not the best at using prompts. hard code these custom prompts like sql query templates.

you DONT need to code anything that you can directly put into chatgpt. you need to code things that you can't put in- such as combining info from multiple pdfs, long pdfs, latex, blogs, code, etc. what you're coding is NOTHING DIFFICULT AND REQUIRES NO NN KNOWLEDGE AT ALL- IT ONLY REQUIRES GLUING THINGS TOGETHER AND KNOWING HOW TO USE CLOUD TECH. but it's so specific yet useful that others haven't thought of the use case, not knowing it coudl be used this way

similarly, the experiments you do are just showing you understand how they work. nothing special. show you can apply to a variation, but no need for extreme usefulness or novel results.
    this variation is finding circuits of patterns (see how anthropic does it), rather than just editing many individual facts
    these patterns are related like a knoweledge graph
    'is an employee of'- where does that appear? multiple places?
    show this can be queried and stored, compared as a table


<<<<<<<<<<<<<<<<<<
1.
Instead of semantic search just thru docs, combine search on paper with expms. Not perfect but will be a starting trial. 

Humans still must come up with clever ways to test and analyze model specifically; this cannot be automated. Only search and code patterns can. AI strength lies in comparison and search across thousands of embeddings that humans cannot do fast. 
It can find suggested techniques to try. It can rewword sentences to find the same pattern expressed differently. It can find analogies.

Search existing related works and techniques. Prompt eng synonyms
    make a table

If a paper refs another paper in its theory, chain all those papers up to have gpt deliver a cohesive explanation. Use examples, code, analogies, simple terms, explain all variables


Find where in citation, and have popup. have human label certainty; vote on it.

Search similar techniques. You provide the generalization. Try this in a book of algos and linalg. Try b/w fields.

Ask more questions (drill down) on it and tell it to create tables that you custom, on the fly, do so, and store tables, comparing with other tables. search details not found by just keyword (ie. find the author who lives nearby)

Related works- this is too easy. You need more 'semantic search'. Really compare the experiments of papers- does the paper compare the right numbers? It should, like a hunting dog, merely point the researcher to the right direction to take the shot. For the AI to draw its own conclusions is proven to be risky.

Ask a CUSTOM question to semantically get the custom table.

https://www.paperdigest.org/2023/01/recent-papers-on-chatgpt/

use gpt to 'suggest similar problems' based on analogy to existing flaws. your description is the query; gpt won't abstract it itself. its questions (autogpt) it asks are not as good and creative, and prone to going down bad paths (too deep).

eg) compare how memit differs from rome. feed both in then ask ques

retrieve pdfs, chunk, feed into llm, and compare- no need to store always in vector db? 
search thru arxiv faster than retrieval from pc? if no, only faster if query exact articles rather than 'search for papers with this criteria'

<<<<<<<<<<<<<<<<<<
2.
Automate experiments and simple pandas building. 

Perhaps it can search within its own embeddings, between models. Put in activation patterns into gpt itself to find a pattern. Try on smaller first.

Generate random data and test gpts outputs. Save this somewhere in web app db public access for reproductible expms. 

Most data, results, are neg and should be filtered. Careful about false negs though. It is not final. Not every permutation can be tried. Need sufficient representatives

Dats integration. Does it truly mean that? Hard to integrate both table and paragraph. We'll need a human to double check, but ai brings up cands for human.
Here is the paragraphs and table rec for you to check

Focus on creating general research tools for many to use in sci and datasci. Then show specifically how this can be applied to abstract network finding expms.

Tell autogpt: make expms to knock out those neurons which actv high for zebra input. Get zebra inputs

obtain a paper and model experiments after it. based on each sentence, translate that into code. if existing code, try to integrate with it.

get code from multiple methods. use gpt to prepare them to be in right format for this expm.

get equations, and come up with new solutions. semantic search for similar solutions used in other papers.

draft expms + code but don't run them; user selects templates, modifies and chooses what to spend resources on

clean dataset. variations

Compare curr expms to results from paper

<<<
gpt generates variations of code/expm desc: each param (ie. each diff layer that is 'more likely' to yield interesting exceptions/patterns).

<<<<<<<<<<<<<<<<<<
3. 
search conferences to publish to. check stats

obtain the formatting guidelines and output drafts of it in latex

<<<
In latex, rewrite entire paper is simpler terms
    bad idea- too much to write, won't fit. instead, turn into different format. but this is also very specific and user specific; also, there's no need to code this b/c you can directly do it in chatgpt

Use existing tool to turn pdf to latex

<<<<
correct an entire paper to be in a certain format (eg. spelling, conference). obtain the latex for one paper, and make another paper into its format

New perspectives, double check


