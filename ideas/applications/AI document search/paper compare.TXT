Gather relevant papers and extract relevant comparisons

<<<<
Eg) "Find models from last 5 years and create a table with each row being a model, and the columns comparing their accuracy performance against the MNIST dataset"

The tool would need to understand what is the 'accuracy performance'- it needs to parse the text to understand which number is the right one. It also needs to know that number refers to comparing against MNIST.

<<<
Core Functionalities:
- REFERENCE where it got this info from. Point to not just the paper, but the place in the paper it got this info from. This will allow human to double check its accuracy.
- Able to correct it to get more accurate outputs
- Able to choose from several alternative outputs

The main thing is to semantically understand enough to transform data into a clean format. But LLM are not enough yet to do nuanced analysis that doesn't adhere to some existing format (it may, but rarely), so don't expect to use it for that. 
    It SEEMS to be good at "finding analogies like mad libs by semantically understanding what goes where", but not deriving novel formats/ideas from those analogies

<<<
Optional Functionalities:
- Can parse Latex and symbols. Need to pre-process to convert them to text
- Image may need to be pre-processed by a model trained to turn images to text
- Convert into layman's terms. Specify number of paragraphs, what level of education, etc
- Don't repeat redundant phrases from prev in convo

<<<
Future Functionalities:
- Able to read images without pre-process
- Able to read latex and symbols without preprocessing
- learn from info distilled into formats that user created

<<<
GOAL: Others will inevtiably create many pdf comparison systems. This is just doing it your own way, like a project done in school for practice. it's not meant to be innovative; that's for later on. This is for training.

<<<
Ideas for how to implement:
- debug see what loaded pdf as text looks like as DS
- embed doc info 

<<<
To do:
- Check how LLMs perform for this in various cases
    chatgpt, gpt-4, llama (alpaca, dolly)
- Check how existing tools (not just llms) perform for this in various cases

<<<
Look for existing tools:

search 'gpt pdf'
    langchain, chatpdf

search 'tool to compare academic papers'
    top results just compare similarities, not semantic

search 'semantic tool to compare documents'
    results are about 'tree data'
        https://blog.trailofbits.com/2020/08/28/graphtage/

search 'semantic search'
    ask gpt to summarize this
    you likely need to use existing tools from this, with slight mods and pre-process and finetuning, etc to fit your desired outputs (the existing outputs for this can't create comparison tools as in the 1st example above) AND customize how it's displayed and used by other tools in our site

    this just finds things; it doesn't output things in formats like chatgpt. doesn't give its own output:
        Vectara
        Pinecone- needs to use langchain to get custom output

https://www.chatpdf.com/
    very good but doesn't have info on other pdfs. it doesn't search them through the web; you have to manually input to cross compare. also it can only take 1 pdf at a time?

https://github.com/hwchase17/langchain
chains together LLMs

https://huggingface.co/spaces/ranjangoel/GPT-PDF
https://github.com/talkingwallace/ChatGPT-Paper-Reader/blob/265a3c654bc76fa95c7449530ffab66770d1e8ee/gpt_reader/bot/openai.py#L134



<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Candidate starting points:

(see langchain.txt)