IDEAS: have say classical vs rock music as "good or bad" labels. This is the same as labeling as classical vs rock. But then it gets even trickier; have some classicals in "bad" section and vice versa. Now it's a very weird labeling, but have AI self learn to differentiate to develop its "taste".

A harder problem is how to use AI's personal history to develop taste. Eg) if it put "oranges" in its image-liked category, if music beats associates it with "orange", link that music to "like"

Everyone has mild synesthesia, get AI to have an artificial form of that (that is, it's not the same as how our synesthesia operates in our brain, since our brain wouldn't use such a specific algorithm as I've designed- it can't, only a computer has that capability. our brain only has neurons communicating in a certain computational pattern. though what if this pattern can be mapped to certain algorithms- that is, certain neurons or particles are actually like 'logic gates'?)

The main idea behind this is NOT creating 'AI with personality' but creating 'AI with synesthesia' (multi-modal). An AI trained to enjoy oranges can feel that in text, creating a 'concept' of it, analogously linking the word and image together, like in CLIP (see multi-modal neurons). 

Does the concept community of words like "sweet, pleasant" have a similar distance/ranking to other word communities (anger, sadness, etc) as the concept community of images? Look at both latent space and neuron circuits (latent space is just a geometric way to measure neuron circuits).

<<<<
If AI likes pizza and cats, it usually imagines pizza cats when listening to music. If reading a text, have it output how it visualizes the characters based on its interests (training how it rewards certain images) and memories.

<<<
GENERATION: given training set of user likes vs dislikes, generate an image that the user likes

Given set of liked + disliked images, classify or generate a song that user likes
synesthesia- does liking beaches mean likes more surfer music?

<<<
TOOLS: 
Since you need text understanding, you need transformers, and thus Huggingface transfer learning.

First, look into what existing models you can use.

https://huggingface.co/distilgpt2

<<<
DATASET:

Eg) given a training set of one's disliked and liked art [/songs]

If the model needs a large dataset (say >100) of your likes/dislikes, the goal of the project fails. The goal is to have the user only submit a couple of their interests, and the model will learn to have the same taste.

<<<
AFTER CLASSIFYING:

The classification is nothing new. But after outputting 'like' or 'dislike', now what? Give a score? All that is boring. What's more exciting is generating output: a review (text), what they imagine (image/video), etc.

Can other NN shape the interests of a NN? A community of AI w/ their own interests
