How To Turn Anyone Into Amogus (Using The Matrix)
How to Turn Anyone into Amogus (using a Neural Network Matrix)

timeline:
intro, abomination examples (last a few secs), mechanism in nature, how the brain works, drawing intuition poetry, the Matrix, how NNs works, overfitting, matrix multp... end w/ many questions and chatGPT and say next video, slideshow of unsettling amogus outputs

results timeline:
-first show W/O training on any art (show your entire dataset)
-then show using diffusion model, why it fails, and why we need to fine tune it (fast scroll thru your notebook)


throughout the entire video, show what has been created by NNs. it is a mechanism that can use ANY data. humans can choose to teach it. this data can be voluntarily given, and it will still work the same. we will not be discussing how this tool is used for profit or commercialization, because it doesn't need to be involved in profit in any way. it is simply a marvelous process that exists, like a plane or a star.

First word:
Patterns.
From evolution (monkey meme), starts grand then descends into abominations (apophenia)

at start, don't even mention NNs or AI. Actually, don't use the word AI at all. Just use NNs. Show the results, and say it was done by a network, and what's called a matrix. A transformation. but put AI in the tags

what is a concept?

say that concepts are represented as relations to one another

neural networks are mentioned EARLY ON, first with the phrase "it can adjust its weights by observing anything. voluntary."

the fact that these sigils are able to produce such things is shocking

first discuss the brain, and how it pieces concepts together. does the amogus live in our brain? state this is very very oversimplified and may not be 100% accurate for the sake of simple explanation, but the main principle has been observed.

first state how the brain figures out amogus. then discuss how NNs figures out amogus. state a bunch of diffs b/w NN and brains. cite your papers.

beware of 'confusing the map for the territory'- on a very general, abstract lvl there are similarities in how they learn, but the exact mechanisms are extremely different. what is true is that in both systems, weights are adjusted in response to new information.

https://charlesfrye.github.io/math/2017/08/17/linear-algebra-for-neuroscientists.html

https://www.analyzemath.com/applied_mathematics/electric_circuit_1.html
you can apply matrices to ANY network. but it is when our minds assign concepts to represent this information flow do we see that concepts have an analogy to certain networks.

when discussing how the brain learns, don't discuss the matrix math yet. introduce the matrix early on, but keep it shrouded. don't mention math. say 'what does this have to do with the matrix?' also introduce concept addition early on, and analogies. for now, call these 'concept networks' ('concept relationships, or concept interactions', or 'interacting concepts' or concept web), then later say they're both natural and artificial neural networks. and how the matrix can be used by us to calculcate both.
early on, don't cite the papers where they came from. claim it, THEN cite it later on in video once it's revealed it's a NN. say the concept web can take ANY observations. you can voluntarily choose to teach it, and it'd still work (don't use the words sample or train?).

the name is just an association

show a fast paced scrolling list of things about bio NNs this expl ignores. just say we are explaining it for the sake of 'how neurons learn'. Don't use matrix or addition here; save that for ANNs.

introduce NNs within 5-10 mins of video! don't meander

<<<
overfitting is bad and everyone tries to avoid it

overfitting is also bad here for classifying b/c we want to stretch the definition of what counts as an amogus. if it was overfitting, it'd only detect amogus if it matched this exact image. by reducing overfitting, it'd think anything is an amogus.

but we will purposely train a NN wrong, as a joke
    dont use this exact phrase

Apophenia. one type is paradoilla (involving the perception of images or sounds in random stimuli). linked with insanity (the movie Pi, illuminati)

Apoptosis (cell death) vs apotheosis (reaching godhood)

"neural network trained to recognize among us"- no results

don't put moistcritical in title, but put him in thumbnail. also wojak chicken pointing amogus (big mouths get views)
also sexy amogus

<<<<
multiple methods:
1. dreambooth transfer learning on SD to generate amogus mixed with someone by prompt
2. cut out, bounding box
    like yolo, outline the amogus, then focus only there
3. img2img: turn PARTS of a person/image into amogus (eg. their eyes, a trashcan)
    control what counts as an amogus using training data, etc. turn only 'one' thing into amogus, or multiple.
4. search for amogus in a database of images and then find bounding box or convert (at even the smallest places)
5. gradient ascent, deepdream (it has been ignored)
    make it less nauseating
6. img2img: turn someone into a giant amogus. forcefully mold their shape; gets rid of arms, detects legs

?. put amogus img thru NN trained only on objects, human faces

<<<<
the issue w/ interpreting if the generated output ARE amogus is that it's so general. anythign with a circle in the middle is too general. anything with a circle and legs is less general, and considered more of a match. anything with circle, legs and red is even more specific and less chance to be a coincidence that all those are together.

<<<


<<<<
forced a NN to reocgnize amogus
(please no more)

chatgpt: (put at end of video, showing it type it out in real time)
write a story about a neural network trained to recognize amogus and go insane

write a story about a neural network trained to recognize amogus meme from among us and go insane

your own skit (see jewceman, IS DIO A POWER BOTTOM?)
'can you teach me to be funny'
'i am sorry for what i have done'

'we gotta figure out what the internet finds funny'
'you taught the AI to recognize memes?'
'but amogus isn't funny'
'it's too late... it's begun teaching the other AI that amogus is funny...'

montage of amogus outputs (like the 'unsettling imagers backrooms' videos)

<<<<<<<<<<
amogus vector

often, need to make it wrong to see what's causing it to be wrong, and thus debug it. it's like turning a patient sick to study an illness. the amogus AI is our test subject.

<<<<<<<<
profound and magical; a language that corresponds to concepts. symbols and architecture, a WORLD of concepts. a land of imagination
DMT world
the exact algorithms are most likely not found in nature, but some general principles about how interacting parts come together to calculate information may be, all the way from symbols to cells. language- used by many organisms to communicate. and this specific pattern is so powerful. genes are information that 'learn'- that is, change to propagate further.
memes? that's what we'll be exploring in the next video

intuition, gaining skills, one of them being drawing. a sculptor.

profound bc it's how concepts actually are calculated

our focus is not on AI, but whatever ritualistic process is used to put together larger concepts from smaller ones, a process that is reminiscent of emergence

we will be discussing this strange ritual which somehow represents these concepts. much like how symbols would represent

this is a process that may not even depend on AI, but may be prevalent, in a general way, in other processes of nature. throughout nature, information constatly flows and composes together. we see this in language. 

it's very strange how this even occurs

the exact process is not the same. the exact process the AI uses is very likely not how it's used anywhere in nature. but the general principle that allows smaller concepts to be composed into bigger concepts through analogy seems to be fundamental. so that's what we'll be exploring.

analogy is key; apophenia is when analogy is used carelessly, making one believe in connections that are just coincidences. if something is frequent, the connection is b/c of their frequency, not b/c of anything else. for example, '3'. now amogus is very general.

somehow, this may be linked to how patterns flow through society, how language is used, why emergence occurs. and it may not be, but to figure out why all this emergence and pattern propagation even occurs, we'll have to think deeply about the most likely leads. and right now, this is one of them.

symoblic representation... that is what is interesting and profound. it is linked to evolution (seeing paws).

knowing how it works could result in creating a new parasite. but not understanding how it works means that humans are at the mercy of the existing parasites, which could wipe it out.
not understanding how it works will result in wrong treatments and superstitions, resulting in picking the wrong reason why a correlated treatment works. perhaps it was noticed that 
that's why it's impt to study how something actually works


<<<<
Turn Mr Bean into an Among Us spaceman
    doesn't work; turns into spaceman

Turn Mr Bean into an Among Us
    sort of... but still no clear amogus

Turn Mr Bean into an amogus
    absolute failure

this means fine tuning on amogus is crucial

<<<
https://huggingface.co/spaces/stabilityai/stable-diffusion
"among us"
this gets 'among us' like things but NOT among us. we want to overfit bc we want the EXACT among us

"among us" meme
also fails

"among us" spaceman
also fails

<<<
using just the 3 amogus memes downloaded on 12/15, it ACTUALLY recognized real images as amogus, such as a speaker

.webp works as input

<<<<<<<<<<<
https://mccormickml.com/2022/12/06/how-img2img-works/
With img2img, we do actually bury a real image (the one you provide) under a bunch of noise. And this causes Stable Diffusion to “recover” something that looks much closer to the one you supplied.

https://github.com/AUTOMATIC1111/stable-diffusion-webui#stable-diffusion-web-ui

https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/

https://composevisualrelations.github.io/

<<<<
use your own drawings made in paint

create an amogus generator using a non-ML algo

actually you just need to overfit on like 10 amogus drawings

<<<<<<<
https://lanstonchu.wordpress.com/2021/10/18/a-glance-at-deepdream/

https://medium.com/analytics-vidhya/deepdream-using-tensorflow-an-introduction-to-generative-deep-learning-15e8b1f03c7e

<<<
sinhalese

<<<
used to find patterns in scientific data
[highly cited papers found in related work]
biology and medicine
    alphafold
social science (altruism)
    ???
psychology
    ???
economics
    ???
neuroscience
    https://arxiv.org/pdf/2106.03535.pdf
    https://www.vox.com/science-and-health/2016/12/29/13967966/machine-learning-neuroscience
ecology and earth science and geology
    climate change
        ???
ecology and zoology and botany and evolution
    ???
physics and engineering
    ???
chemistry
    ???

using this, we can find actual patterns in scientific data [and quickly say- and also false patterns such as amogus]
first look for correlations, then study causations. but we need to find correlations first.

all patterns are real, but whether they are due to a proposed causation is not always true. just b/c amogus is there does not mean among us is related to it. (show graph describing 'abstraction' pointing to 2 things)

just b/c anime eyes have amogus does not mean all anime characters eyes came from the amogus
convergent evolution

https://statswithcats.net/2015/01/01/how-to-tell-if-correlation-implies-causation/
mediated

don't have to use scientific terms, just describe them

I don't apply it to the science, I build the tool used by scientists. Like building a computer or telescope to be used by scientists

<<<
condensing matrix multp: (second half of video, ~10mins)

first describe how to translate object to coordiante space using addition
'like a language'
but the language != the objects, just like 'false friends' example
each basis is like its own language
thus, each set of neurons (not even in a layer) is describing a concept is its own language. depending on how you slice (take a subset) of the neurons, it'd describe the concept in a different way. 

unit conversion

do NOT go into details of equations or precise step by step (do it faster here and say link to vid where it's done slower)

don't really explain it step by step; link to your true '3b1br' style video. here just quickly state jumps and hand waves to final step, which is a surprise, and state multiple times (twice, spaced out) to watch the other video

reiterate, the 'map is not the territory'

<<<
we will not be selling these outputs
we are not doing this for science
we are not claiming ownership over these outputs
we are doing this for fun

(dont mention anything about profit beyond this)

<<<
Make hours long video (not sped up) showing drawing amogus from scratch and/or creating the dataset

In this video, show it drawn in paralell sped up

<<<
to make anthropomo jokes or not?
can just say 'make this thing suffer the way we do'

Dissect it.
Hurt it.

