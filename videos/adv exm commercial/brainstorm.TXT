Warns AI of adversarial example dangers

the commercial itself has misclassified adv effects. halfway thru, breaks 4th wall- the narrator himself goes crazy.
    wait, that's not right
[ending- unexpected effects during this media production. this commercial failed to air. it has since been archived as a case study]

which one is the human?

the commercial itself is also alive
the narrator combats with it

ending: narrator ends up giving misinformation, fully believing he solved it
    robotic voice. there's only one voice in the commerical.

keep it only 2-3 min long, as it's a commercial

<<<
humans are a simulacrum. they become detached from teh original meaning, and now the AI 'protect humans' even though there's none left

'protect humans? come to think of... I've never actually seen a human in person'

OR- do the humans now think they're AI, and are indistinguishable? 
'am I a human?'

some ai believe they're humans, but they actually might not be

<<<
https://www.youtube.com/watch?v=sbRKFywcKEc
Analog Horror - Friendly Pills

https://www.youtube.com/watch?v=_AS6CfXrGAA
Analog Horror - Happy child

https://www.youtube.com/watch?v=flvxdX3swPw
Analog Horror - The Best MOM

https://www.youtube.com/watch?v=31O33zX3DBg
Burger King Pokemon Toys Recall Commercial

https://www.youtube.com/watch?v=mlnNdYKfof8
Basswood County Humanoid Alert [ Analog Horror ]

<<<<<<<<<<<<
This is a human. Or, so you think it is.

These pose a safety hazard

Adversarial attacks

Do not mistake a human for an orange.

<<<
MATH: (very little)

why do adversarial attacks work?
high dim space

https://openreview.net/pdf?id=4E3Jm0p6Sc
Less is More

Do we know why adversarial examples exist?
no one knows! (yet)

https://viso.ai/deep-learning/adversarial-machine-learning/
https://arxiv.org/abs/1412.6572
By adding an imperceptibly small vector whose elements are equal to
the sign of the elements of the gradient of the cost function with respect to the input

https://www.youtube.com/watch?v=hMO6rbMAPew&t=1615s
Adversarial Examples Are Not Bugs, They Are Features

<<<
ACTUAL CASES:

https://en.wikipedia.org/wiki/Adversarial_machine_learning
McAfee attacked Tesla's former Mobileye system, fooling it into driving 50 mph over the speed limit, simply by adding a two-inch strip of black tape to a speed limit sign

https://www.youtube.com/watch?v=piYnd_wYlT8
Fooling Image Recognition with Adversarial Examples

Use that fluctuating classes animation when it goes haywire

