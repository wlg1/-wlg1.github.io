We've been showing input space and output space as two separate spaces. But on an abstract level, they're just using the exact same numbers as a measuring tool. 
    frame 0 of 8.1.

To explain this, let's take two apples, and two oranges. We can use the same measuring tool, a number line ruler, to measure how many objects there are. Now two apples are not two oranges. However, if you abstract away the units, they're measured using the same number two. The space of apples is not the same as the number line ruler, and neither is the space of oranges.
    9.0.py: start w/o number line, just fruits
    then number line of apple and orange, then fade away apple and orange and transform both lines to one

    apples img of >2 apples != number line img

<<<
The same thing is happening when we're measuring our cat people data measurements using a 2D coordinate plane. Before, we used different colors for the vectors in our input and output spaces. Now let's use the same colors for both, to show they're both using the same coordinate plane, but with its vectors pointing at different data measurements. We'll also use slightly different sizes to represent our units, just to make them clearer. 
    fade in same colors. no matrix on bottom left.
    9.1.0: just 2 vecs, 4 DMs for now (less info to process)

In our input space, our red basis vector measures a nose tip of 1 unit. But in our output space, the same red basis vector measures a nap smile of 1 unit.

<<<
So let's show how to transform the data measurement positions in input space into the data measurement positions in output space on the same coordinate plane.
    9.1.1: no longer two separate ones, but fade in just one. start w/ input, w/ only red and blue

For the ease of demonstration, we've been associating vectors with Data Measurements. Then we've been using matrix multiplication to map one vector to another.
    transform them to light red and blue (remove prev)

But what does it mean to map one vector to another? We aren't saying that the red vector equals the light red vector, or that the blue vector equals the light blue vector.
    show all four vecs 
    image of != fades in on screen, showing vector coords

Let's think about this in a different way. Instead of mapping one vector to another vector, let's map a Data Measurement on one vector to another vector by multiplying it with our matrix.
    9.1.2: shrink prev DMs, grow in 2 DMs
    transform 2 DM on 2 vectors to the other; vectors stay put

    show W X matrix multp on screen (same spot of image !=)

Now we'll look at more vectors, and have them point to Data Measurements. When we pass these vectors through a matrix, we are performing a change of basis because the basis vectors that were pointing to the nose and ear unit 1 measurements are now pointing to the nap and luck unit 1 measurements.
    fade in 4 other vecs- orange, light red, etc., then grow in 2 more DMs and move DMs

Similarly, the data measurement previously measured by the white vector [1,1] is now measured by the silver vector [4, 1]. 
    9.1.3: add in white vector and move its DM
    
<<<
Since each coordinate space provides a different way to represent the data, let’s call each coordinate space a Model. Furthermore, we'll say that a model assigns meaning to each coordinate point. The meaning of a coordinate point is the label that's on it; in this case, the labels are data measurements. Subsequently, the meaning of a vector is the data measurement it points to, and is derived from the basis vectors used to construct it.
    9.2.pY: show the input and output as separate images again, taking frames of 9.1
    D:\Documents\_prog\my_repos\wlg1.github.io\ch1

    fade in meaning next to DM

In Model 1, the red basis vector pointed to a cat person with a nose and no ears because it’s supposed to mean “has a nose with unit 1”. In Model 2, the red basis vector points to a cat person with a smaller nose and with ears because it’s supposed to mean “these nose and ears sizes indicate a nap smile of 1".
    yellow circle around red (visio edit, fade)

Likewise, in Model 1, [1, 1] meant “an cat person with a nose tip of 1 and an ear length of 1". But in Model 2, this vector means "a cat person with a nap smile of 4 and a luckiness of 1".
    
This shows the difference between the data samples coming from reality, and the model that represents those data samples using labels. The vector [1, 1] is not the cat person itself; it is merely a label of it, and whichever label is used depends on the basis vectors. 
    [1,1] != DM

When a matrix, a neural network, performs a change of basis, it merely changes which model maps to reality.
    show DM anim repeat alongside 3D to 2D cat (arrows in)

<<<<<<<<<<<<
Where is the reality where cat people reside? Notice that the entire time, we've been working only with a measurement of reality, where information is captured, extracted and abstracted into neurons. This input space is also just a model of reality; it is not reality itself. 
    9.3 visio: cat face reality DM
    move DM to input space of cat faces, then fade out

<<<<<<
Let's look at data samples of our cat people reality. Without basis vectors, or neurons, to model it, we don't know how to describe it. 
    9.4.py: fade into population of cat people transforming by calc MM result and moving to copy on them

    https://www.reddit.com/r/manim/comments/mb3uhr/how_to_eliminate_the_slight_pause_between_two/

But once we add basis vectors, we lock onto an interpretation, where we can describe reality in terms of a frame of reference. It is described relative to our basis, which is an anchor to high dimensional reality. 
    freeze frame on this. place a coordsys w/ basis names playful and fast on them

We can describe these cat people using playful and fast, or funny and scheming, and more.    
    after saying names, transf 3 times, saying each time it locks on

Reality itself doesn't change. It is only our model of reality that changes. There is some sort of linear correlation between the input and output measurements. Every distance is transformed in a similar way, given by the weight matrix. Thus, all structured relationships are preserved under the matrix analogy.
    around 20 secs, so each transform takes 1 sec, so repeat 20 times. use both movealongpath (no pause) and transform (slight pause). issue w/ move along path is that all objs may move at diff rates.
    or just cut it at beginning, and move slower so less to cut

<<<<<<<<<
Notice that when we performed matrix multiplication, we were bringing the data measurements along the line matching the orange vector onto the red basis vector.
    show 2D MM of DMs. 3 on nap dim: one behind, one in front. and luck DM. then revert nap DMs

This entire line is just scaled versions of the orange vector. What all of these scaled orange vectors share is a common ratio of nose to ear. You might have seen this before as the slope of a line.
    scale orange vector to the 2 DMs, pos and neg. w/ coords
    show ratio from eqn
    then turn them into a line

If we look at the neural network corresponding to this coordinate space representation, given that these vector dimensions each correspond to a neuron, this family of orange vectors corresponds to certain combinations nose and ear activations.
    show NN w/ nose and ear nodes, then values passing in
    7.1

Let's turn the neurons and weights into variables. These combinations of nose and ear neurons make up their own dimension. 
    on vec, show DM equals linear combination of neurons. move from NN bg to this eqn bg

When we look at reality from this dimension, defining it by placing a basis vector on it, we are looking at a region alongside these data measurements- in this case, it's a line.
    show DM MM again, but moving lin combo eqn too
    (the vector is not the dimension, but the region is)

<<
If we take our nap equation and re-arrange it to solve for y, the ear value, we get a yellow line. By plugging in any value for x, the nose value, such as 0 to get 1 for y, or 2 to get -3 for y, we can find an infinite number of points that map to the nap value of 1, since there are an infinite number of nose and ear combinations on the yellow line that map to a nap value of 1.
    show orth line and 2 dots
    transform nose DM and nap DM on eqn into values
    rearrange eqn: w*nose_fixed + w2*EAR = nap_fixed
        ear = (nap_fixed - 2*nose_fixed ) / 1

But for this matrix, there is another constraint- these nose and ear points must also map to a luck value. So when we transform into a nap and luck output space, these two points will be mapped to the same nap value, but will have different luck values, so they will not be mapped to the exact same point in output space.
    invert, then repeat transform slower

    quick flash: note- the yellow line rotation is not an entirely accurate transformation as it should also show scaling; this hand waving is done for ease of demo