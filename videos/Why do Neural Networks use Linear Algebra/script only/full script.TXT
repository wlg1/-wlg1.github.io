When learning about the new advancements in neural networks, people often encounter concepts they haven't seen before, such as manifold, or isometry.

So what do these mathematical concepts mean, and why do they use them?

In this series, we'll be providing answers to these questions in a visual and intuitive way.

Let's start with a basic concept: using matrix multiplication to recognize features. Neural networks multiply weight matrices with inputs. 

But why does that specific algebraic procedure work? Why does its first step use the dot product of the weight matrix's first row and the input vector to get the first output? And what does the matrix have to do with how a neural network interprets a higher dimensional reality from its own lower dimensional perspective?

Knowing why this procedure is done is key to a visual intuition behind how neural networks compose together patterns into more complex, higher level patterns. For example, they can add concepts together to make analogies, composing together "King minus Man plus Woman to equal Queen" in a hidden, high dimensional world called Latent Space, or perform abstractions to do Style Editing. Throughout this series, we'll be explaining how all these work.

Aside from knowing how to multiply variables, there's no prereqs to watching this. We'll explain a lot of concepts from scratch. If you're unfamiliar with some terms, it's recommended to watch these 6 3Blue1Brown videos, which are in the description. But just like two classes that teach the same material from different perspectives, we'll be reviewing many of those videos' concepts to explain new ones in our series.

The explanations will build up gradually, so feel free to skip ahead to any chapter using the timestamps in the description below.

Ok, let's begin.

To show why neural networks use matrix multiplication, let’s start with an example where in the future, cat people roam the world. Some evidence suggests that how much a cat person enjoys naps can be predicted by measuring how far away their nose tips are from the center of their face. We call this measurement, 'Nose tip'.

For instance, many cat people with long nose tips are said to enjoy naps. It's always the case that the more a cat person smiles when napping, the more they enjoy it. We measure how much they enjoy naps using a metric called 'Nap Smile', or just shortened to 'Naps'. 

But we don't know how nose tips exactly affects enjoying naps. How big of a Nap Smile does a cat person with a nose of size 3 have, compared to a cat person with a nose of size 2? A slightly bigger smile, or a much bigger smile? 

We're going to have to figure this out by using a neural network that takes in a cat person's nose tip as input, and predicts their nap enjoyment level.

Let's start with the input. We're only going to measure nose tip, capturing it into a Data Measurement.

These are measured using 1 unit of nose tip, which is a basic measuring unit, just like using 1 meter for distance, or using 1 second for time.

Let's measure along a number line which we'll call the Nose Space, or the Nose Dimension. We can make a nose tip of 1 unit twice as big to get a nose tip of 2 units, or make it three times as big to get 3 units.

Each point in Nose Space is associated with a different Data Measurement.

Now, we can also measure Nap Smile along Nap Space. Each positive unit measures how big their smile is.

Let's take an example where the longer a cat person's nose tip was, the more they liked naps. A cat person with a nose tip of 1 unit had 2 Nap Smile units, a cat person with 2 nose tip units had 4, and so forth.

We notice a pattern here that's somewhat like unit conversion. For instance, for every 1 meter, there are 3.28 feet. So if an person is 2 meters tall, they're also 6.56 feet tall.

So let's convert nose units into nap units. Turning this into an equation, we have 2 (nap over nose) * (1 nose) = 2 nap.

And visually speaking, this means that for every one unit of nose tip, there are two units of Nap Smile. 

Notice the point 1 in the Nose number line and the point 2 in the Nap number line are labeling the same Nose Tip Measurement. This is because we're saying that every nose tip of 1 ALWAYS has a nap smile of 2. 

Our equation isn't mapping a number, such as 1, to another number, such as 2, but it is mapping a Data Measurement from 1 in the nose space to 2 in the nap space. This is a Change of Units.

Likewise, for every two units of nose tip, there are four units of Nap Smile.

Our unit conversation factor of 2 can be represented, in general, as a variable W, which means how much we should weigh our nose value by to get our nap value. 

We can also represent out input with a variable x.

So, what does this visual we've just seen have to do with a neural network? The answer actually has been hidden in front of our eyes this entire time. 

Let's look at this equation below, which is used by a neural network. What does our simple unit conversion equation have to do with it? We're going to show that they're very similar.

First, we'll represent the output value as one variable, and not look at units.

Second, note that all the variables in the equation below are matrices. So we'll analogously map multiplication into matrix multiplication by putting our terms in brackets. 

The b is the bias, which we don't need to discuss now. We can show it in our equation above by adding 0 to the left side, noting that adding 0 doesn't change our equation.

The sigma is called an activation function, which we also don't need to discuss now. For our unit conversion equation, we'll use the Identity function I. We see that when x goes through the identify function I, we get x again. It's like multiplying an expression by 1. So again, this doesn't change our equation. 

Now, both equations look similar. But what is the equation we have below? It's a neuron equation, which is what a neural network uses to compute a neuron activation. So our unit conversion equation is just a very simple neuron. 

W contains weight connections that the X inputs are multiplied with, and A contains the neuron activations, which in our case, is the nap neuron. 

In this case, the matrix W actually just consists of a single weight variable lower case w, also called w one. Same for the X  and A matrices.

In fact, one can think of this nap neuron as just a single layer neural network with one neuron.

Or with two neurons, if you think of the input as a nose neuron represented by the equation 1*x.

Now, we see that our unit conversion visual has been hiding a neural network neuron all along.

So a neural network can be viewed as a function that's composed of many smaller functions. Note that it can't approximate every function, but different types of neural networks can approximate a wide variety of functions that are useful for prediction.

Of course, a neural network is more than just this equation, so rather than saying this equation is a neural network, we can say it's approximate, or analogous, to a neural network.

But what allows large neural networks to do complex tasks that a simple neural network can't do? Let's see what happens when we add more connections to our network, starting by just adding one more.

When using our equation to predict nap enjoyment, we find that there's cases where using nose isn't enough. We found that Tom has a nose of 1 unit, and has a Nap Smile of 2.75, but Jane also has a nose of 1 unit, yet has a Nap Smile of 3.5. 

Since we also found that ear length has some correlation with nap enjoyment, let's use both nose tip and ear length to predict nap smile.

Just like with nose tip, we also have an ear length of 1 unit, 2 units, and 3 units

How can we represent a Data Measurement of a cat person in terms of both nose tip and ear length? We'll use a 2-dimensional coordinate space.

If we rotate our ear length number line by 90 degrees and put it next to our nose tip number line, we get a coordinate plane where we can represent each cat person using both nose tip and ear length as axes.

Now, how can we add together the Nose Tip and Ear Length Data Measurements to describe a Cat Person? 

Let's say we're taking measurements of a cat person named Tom. To describe him, we start at the origin point. We find that his nose tip is 1 unit, so we move from the origin to (1,0). Then we find his ears are 1 unit long, so we move up from (1,0) to (1,1).

These arrows that formed a path of step-by-step instructions are called Vectors, which are defined by a length, and a direction. You can place them between two coordinate points, from a tail point to a head point. 

We'll use vectors to tell us where we go from one coordinate point to another, and by how much. To add vectors together, we just move the tail of one vector to the head of another.

Because unlike the coordinate points, which are permanently fixed where they are, the vectors can be moved anywhere in coordinate space. 

This vector is the SAME one that's been moved here. But it is not the same as this vector, or this one.

Since the vectors can be moved, it seems like there's no fixed association between a vector and a Data Measurement. But for the ease of demonstration, we'll informally say there is to help us get a high-level understanding of how vectors add features together.

Looking back at our example with Tom, we'll represent our vectors using matrix brackets, whose values describe the head of a vector, with its tail on the origin.

We'll show that adding these two features together is the same as adding the two vectors pointing to these features.

When a vector's tail is on the origin, this vector points to the same Data Measurement as point (1,0). So far, we have this Data Measurement as a partial Data Measurement.

When you add it to the vector going up to (0, 1), (noting that this partial Data Measurement from [0,1] is not what's actually on point [1,1])

it's as if you're given an instruction to add the partial Data Measurement on [1, 0] with the partial Data Measurement on [0, 1].

Therefore, Tom is on vector [1,1]. You can get to Tom either by the path of these two added vectors, or by the vector pointing to [1,1].

Because this combination of nose tip and ear length describes our cat people input, we call this 2D coordinate space our Input Space.

So now we know how to describe a cat person using both nose tip and ear length. How do we use both of these features to calculate Nap Smile?

First, let's see how to predict Nap Smile using Ear Length. We notice that the longer a cat person's ears are, the more they enjoy naps. But relatively speaking, ear length doesn't have as much impact on nap enjoyment as nose tip does. For example, a cat person with an ear length of 2 would only enjoy naps by 0.75 units more than a cat person with an length of 1.

So we get the equation: (0.75 nap/ear) * 1 ear = (0.75) nap

The Data Measurement at point 1 in ear is sent to point 0.75 in Nap, just like how the Data Measurement at point 1 in nose was sent to point 2 in Nap.

And since studies on cat people suggest that nose tip and ear length can independently build on top of each other to predict nap enjoyment, we can add them together:

How do we add these two features to get nap smile? By using the exact same vector addition that we used in our Input Space.

Now when we add together the vectors in our 2D coordinate plane, we are also adding together their analogous vectors found in our 1D Nap Space.

We move the tail of the blue vector to the head of the red vector, and after adding, we get a purple vector pointing to the same data point in both Input and Nap Space, which is where our cat person Tom is at. 

Our Nap Space says Tom has a nap enjoyment level of 2.75.

Let's say a nose tip that faces down has a value of -1 units. The lower the tip points, the lower the value. 

In our Input Space, it's easy to see how we can add together nose tips and ear lengths of different units. First, convert from Input Space to Nap Space using weight multiplication.

Next, let's take a nose tip of -1 units, and a ear length of 2 units, and add them together. 

When we scale the Input Space nose vector on the left by -1, we're also scaling the Nap Space nose vector on the right by the same amount. Now both vectors point in the negative direction. 

After we scale the ear vectors in both spaces, we add them together. In Nap Space, this is done by first following the nose vector left, and then following the ear vector right.

Finally, we get a Nap Smile of -0.5, which means that cat person doesn't like naps that much.

Notice that we're just adding together scaled versions of [1,0] and [0,1]. We call these vectors that are mapped to basic measuring units of 1 'basis vectors', because they're basic buildings blocks we can scale and add together to get any other vector in our input space. They're like an alphabet (or a dictionary) used to form words in a language.

The basic measuring units labeled by the basis vectors in our Input Space are mapped to the vectors of length 3 and 2 in Nap Space. But these are no longer the basis vectors in Nap Space. The basis vector in Nap Space is a Nap Smile of Unit 1.

So even though these two spaces are both calculating Tom, they are describing Tom using different basis vectors, where the Input Space talks about Tom in terms of Nose units and Ear units, while the Nap Space expresses Tom in terms of Nap units. 

He simultaneously exists in both sets of dimensions at once, but he looks different in each one because they're just looking at him from different perspectives, like seeing his shadow at different angles.

Just like before, this has an analogy to a neural network, where w2 is another connection from the ear neuron to the nap neuron.

Recall how our equation with only nose to nap could also be represented as a matrix with 1 row and 1 column. Now, we go from a matrix of 1 row and 1 column, to a matrix with 1 row and 2 columns

The number of columns in W are the number of inputs, and the number of rows are the number of outputs, meaning there's a connection for every matrix entry.

This explains why we use that strange algebraic procedure of matrix multiplication where we multiply the first row by the first column. This procedure is none other than the Dot Product.

And our dot product is just performing a Change of Units, or in other words, a Change of Basis.

So our Input Space and our Nap Space are measuring neuron activations. We call these spaces 'Activation Spaces'.

Since the nose and ear neurons in the first layer act as basis vectors in Input Space, and the gold Nap neuron in the second layer acts as a basis vector in Nap Space, we come to a very important concept:

Neurons are Basis Vectors in an Activation Space.

This Activation Space, commonly referred to as a Hidden or Latent Space, is where analogies such as King - Man + Woman = Queen can be made by adding its vectors. Based on your space's basis vectors, there are multiple ways to represent this.

This is called Latent Space because it's a world that's hidden from first impressions; you have to calculate it to reveal its structure.

In our examples, for the purpose of gaining intuition, we defined our neurons in terms of “human-understandable measurements”. And though studies show these may actually exist, such as car neurons that detect car parts, neurons within network layers may not always cleanly correspond to a Human-Defined Concept. 

If you put images of a cat and a person through a neural network, in order to create a cat person, it has to recognize the patterns of 'cat' and 'face', yet the network might not have a 'cat' neuron or a 'face' neuron. In fact, most of the millions of neurons in many neural networks may not correspond to a human-defined concept. 

Still, evidence supports hypothesis that some representations of neural network components are interpretable. Otherwise, how else would a neural network be able to derive novel analogies that don't even come from pieces of training data? 

For instance, research has shown how to not only find where certain factual associations are in language models, but also how to edit them.

So just how are these abstract patterns recognized? Instead of being calculated by one neuron, they may be processed by a group of neurons, such as in the sparse coding hypothesis. These group of neurons may process information in a circuit.

We can think of every neuron in a neural network as a measurement on the data, coming up with an interpretation for it from its own perspective through a projection. 

This is like the parable of the blind men and an elephant, where one man only touches part of the elephant's trunk and thinks it's a snake, and another touches only its feet and think it's a tree trunk, and so forth. Each man is like a neuron, and using a matrix, they each pass the information they gather to a judge neuron, who calculates that it should actually be an elephant.

One alternative possibility is that, instead, each neuron has multiple roles in affecting the calculations of other neurons, similar to if-else branches in a decision tree, though not in the exact same way, as they are two different models.

But a lot of research still has to be done to dissect what circuits of neurons are actually doing.
(, which may allow us to stitch pretrained neural network patterns together, similar to genes)

The first row in our weight matrix calculates one output value. Adding a second row calculates another output value. This neural network can be mapped to a unit conversion visual. Before, our first output was Nap Smile. Let's calculate a second output called Luck, which measures how lucky a cat person is.

If we rotate ear and luck to be vertical, we are mapping from one 2D coordinate space to another 2D coordinate space. The values in Input Space on the left will go through the matrix at the bottom left to be converted into our Output Space on the right.

Now before we get into the visual matrix multiplication, we're going to explain how we compute it using equations. Previously, we took the dot product of our first weight matrix row and the input vector. This time, we're going to take the dot product of our second weight matrix row and the input vector.

In our visual, we'll start by calculating the first row dot product, then the second row dot product, and finally, we'll add them up.

So we'll plug in values for each weight. We'll use different weights from before, using 3 instead of 0.75 for ear to nap. As we convert from input to output, notice which weights on the bottom left matrix light up. 

First, we'll convert our nose vector into nap space using the weight 2 nap over nose. What this weight does is map the nose basis vector to nap space. This is because x1, our input value, scales our nose vector the same amount in both spaces.

Now we'll do the same for converting our ear vector into nap space.

For our input values, we'll use one for both x1 and x2, and scale the basis vectors by them in both spaces.

Finally, we'll add our nose and ear vectors together in both spaces.

Next, let's do the same thing, but for luck space. We'll convert our nose vector into luck space, 

and then our ear vector into luck space.

At last, we have our nap and luck values, so we'll just combine them.

Now, there's another way you can obtain the same output. We're going to re-arrange our equations so that instead of doing the dot product row by row, we're going to first convert the nose basis vector into nap and luck space, then convert the ear basis vector into nap and luck space.

As we re-arrange this equation, you can pause at each step if you want to take a better look at it.

First, let's use the distributive property to break our input into the nose basis vector and ear basis vector. Next, we'll factor out the input values.

Now we'll take the dot product for each term, by applying the same formula at the top.

Simplifying, we get this expression at the bottom, which is actually just adding the nose vector transformed into nap and luck space, and the ear vector transformed into nap and luck space.

Note that this is actually what we've been doing before on the left side, the Input Space. For our input space, we use these weight values, which make up the identity matrix, as after it multiplies with a vector, it just returns the same vector, just like multiplying by 1.

This is clear when we look at it visually. First, we transform our nose vector into nap and luck space, which we've also been calling the output space.

Notice that the nose vector is seen from two different perspectives: the nap dimension sees it from its frame of reference, and the luck dimension interprets it from its point of view. We add these two interpretations of nose vector together to get the nose vector within the output space.

Then we transform the ear vector into nap and luck space using the same procedure.

Finally, we add together the nose and ear vectors in both input space, and output space. We see that we get to the same point as before. Not only did we transform the nose and ear vectors into output space, but because Tom, at [1,1] in Input Space, was calculated using nose and ear vectors, Tom is also transformed into output space. This says that Tom has a nap smile of 5, and a luck value of -1, which means he's a bit unlucky.

We've been showing input space and output space as two separate spaces. But on an abstract level, they're just using the same exact numbers as a measuring tool. 

To explain this, let's take two apples, and two oranges. We can use the same measuring tool, a number line ruler, to measure how many objects there are. Now two apples are not two oranges. However, if you abstract away the units, they're measured using the same number two. The space of apples is not the same as the number line ruler, and neither is the space of oranges.

The same thing is happening when we're measuring our cat people data measurements using a 2D coordinate plane. Before, we used different colors for the vectors in our input and output spaces. This time, let's use the same colors for both, to show they're both using the same coordinate plane, but with its vectors pointing at different data measurements. We'll also use slightly different sizes to represent our units, just to make them clearer. 

In our input space, our red basis vector measures a nose tip of 1 unit. But in our output space, the same red basis vector measures a nap smile of 1 unit.

So let's show how to transform the data measurement positions in input space into the data measurement positions in output space on the same coordinate plane.

For the ease of demonstration, we've been associating vectors with Data Measurements. Then we've been using matrix multiplication to map one vector to another.

But what does it mean to map one vector to another? We aren't saying that the red vector equals the light red vector, or that the blue vector equals the light blue vector.

Let's think about this in a different way. Instead of mapping one vector to another vector, let's map a Data Measurement on one vector to another vector by multiplying it with our matrix.

Now we'll look at more vectors, and have them point to Data Measurements. When we pass these vectors through a matrix, we are performing a change of basis because the basis vectors that were pointing to the nose and ear unit 1 measurements are now pointing to the nap and luck unit 1 measurements.

Similarly, the data measurement previously measured by the white vector [1,1] is now measured by the silver vector [4, 1]. 
    
Since each set of basis vectors provides a different way to represent the data, let’s call each set of basis vectors a Model. Furthermore, we'll say that a model assigns meaning to each coordinate point. The meaning of a coordinate point is the label that's on it; in this case, the labels are data measurements. Subsequently, the meaning of a vector is the data measurement it points to, and is derived from the basis vectors used to construct it.

In Model 1, the red basis vector pointed to a cat person with a nose and no ears because it’s supposed to mean “has a nose with unit 1”. In Model 2, the red basis vector points to a cat person with a smaller nose and with ears because it’s supposed to mean “these nose and ears sizes indicate a nap smile of 1".

Likewise, in Model 1, the white vector [1, 1] meant “an cat person with a nose tip of 1 and an ear length of 1". But in Model 2, this vector means "a cat person with a nap smile of 1 and a luckiness of 1", so what's on it no longer has a nose tip of 1 and ear length of 1.
    
This shows the difference between the data samples coming from reality, and the model that represents those data samples using labels. The vector [1, 1] is not the cat person itself; it is merely a label of it, and whichever label is used depends on the basis vectors. 

When a matrix, a neural network, performs a change of basis, it merely changes which model maps to reality.

Where is the reality where cat people reside? Notice that the entire time, we've been working only with a measurement of reality, where information is captured, extracted and abstracted into neurons. This input space is also just a model of reality; it is not reality itself. 

Let's look at data samples of our cat people reality. Without basis vectors, or neurons, to model it, we don't know how to describe it. 

But once we add basis vectors, we lock onto an interpretation, where we can describe reality in terms of a frame of reference. It is described relative to our basis, which is an anchor to high dimensional reality. 

We can describe these cat people using playful and fast, or funny and scheming, and more. But none of these are the main way to describe it; they are all relative. Without a model, reality is anchorless.   

Reality itself doesn't change. It is only our model of reality that changes. There is some sort of linear correlation between the input and output measurements. Every distance is transformed in a similar way, given by the weight matrix. Thus, all structured relationships are preserved under the matrix analogy.

(It's the relationships that are important, not what is used to represent it. Similar to how a computer can be made using electronics, or marbles, or minecraft blocks. There's also an interesting duality in a vector, just like a number, being an object, and also being a change between objects. A neuron is itself a cell, but it also gives definition to other neurons by passing information to them, or having them find where they are in reference to other neuron vectors.)

Notice that when we performed matrix multiplication, we were bringing the data measurements along the line matching the orange vector onto the red basis vector.

This entire line is just scaled versions of the orange vector. What all of these scaled orange vectors share is a common ratio of nose to ear. You might have seen this before as the slope of a line.

If we look at the neural network corresponding to this coordinate space representation, given that these vector dimensions each correspond to a neuron, this family of orange vectors corresponds to certain combinations of nose and ear activations.

Let's turn the neurons and weights into variables. These combinations of nose and ear neurons make up their own dimension. 

When we look at reality from this dimension, defining it by placing a basis vector on it, we are looking at a region alongside these data measurements- in this case, it's a line.

If we take our nap equation and re-arrange it to solve for y, the ear value, and then plug in 1 for nap to find which values of nose and ear get a nap value of 1, we get a yellow line. By plugging in any value for x, the nose value, such as 0 to get 1 for y, or 1 to get -1 for y, we can find an infinite number of points that map to the nap value of 1, since there are an infinite number of nose and ear combinations on the yellow line.

But for this matrix, there is another constraint- these nose and ear points must also map to a luck value. So when we transform into a nap and luck output space, these two points will be mapped to the same nap value, but will have different luck values, so they will not be mapped to the exact same point in output space.

Here's an analogy that helps drive home the difference between model and reality. We’ll look at two data samples: a dangerous substance, 

and an object which is given to someone out of gratitude.

And instead of using numbers, let’s use letters to label our entities. This means our models will resemble languages, some of which also use letters to label entities. So our first model, or language, is labeled as follows

To an English speaker, this may look wrong, because the object on the pink vector should be called something like ‘poison’, not ‘gift’. But in German, this dangerous substance is in fact called ‘gift’. 

If a German speaker tells the English speaker that they’re giving the English speaker a gift, the English speaker may be delighted because they think they’re getting something good. But they shouldn’t be, because what they’re ACTUALLY receiving would kill them.

Since there is a misunderstanding, the English speaker needs to know what ‘gift’ is actually referring to; or in other words, to know the right English word to use for what the German speaker is thinking about. So they need to translate from the language above, which resembles German, to English as follows

Think of the weight matrix as the translator app. The input to the matrix is [-1,2], which is the pink vector where our dangerous substance is at in German space. The output of the matrix is [-4, 1], which is poison is at in English space. So the transformation moves the substance from gift to poison, allowing the English speaker to know what it truly is in their language.    

In summary:
The object on German 'gift' is not mapped to the English 'gift'
The object on German 'gift' is mapped to the English 'poison'

Relating this back to using numbers as labels:
The German vector '[-1, 2]' is not mapped to the English vector '[-1, 2]' 
What's on it is actually mapped to the English vector [-4, 1]

Now let's label the good object with the German word 'geschenk'. Notice that when we translate it into English, this 'geschenk' vector doesn't point to any data sample. In fact, the label ‘geschenk’ does not mean anything in English. The same goes for the label poison in German. Not all labels have to point to an data sample; so in some coordinate spaces, they just mean nonsense. This follows from the advice to not confuse the map with the territory in an analogy.

A word like gift that has different meanings in different languages is called a false friend. Knowing this, we take heed of the following warning: To Beware of False Friends in the Matrix.

We've learned that an entity is projected from high dimensional space down to a subspace of a group of neurons, casting a shadow, or a distorted reflection. 

Though viewed from different perspectives, these shadows are often entangled, meaning that a change in one dimension is analogously reflected in another, like in a house of mirrors.

Now that we've connected the geometry of linear algebra to neural networks, we can finally begin to study its world of concepts. What lies in this mysterious realm of AI imagination?

So far, we've summarized concepts from 3Blue1Brown videos that are relevant for our future videos. Let's watch a recap of what we have just seen.

In our future videos, we'll discuss topics such as interpreting generative models using matrix factorization, and editing key-value associations found by MLPs in large language models.

For now, we've figured out how to predict which cat people enjoy naps, so we can put that matter to rest. We have only begun on the long journey of finding out just how neural networks actually work.