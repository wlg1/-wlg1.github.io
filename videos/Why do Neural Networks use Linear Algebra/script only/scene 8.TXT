The first row in our weight matrix calculates one output value. Adding a second row calculates another output value. This neural network can be mapped to a unit conversion visual. Before, our first output was Nap Smile. Let's calculate a second output called Luck, which measures how lucky a cat person is.

If we rotate ear and luck to be vertical, we are mapping from one 2D coordinate space to another 2D coordinate space. The values in Input Space on the left will go through the matrix at the bottom left to be converted into our Output Space on the right.

Now before we get into the visual matrix multiplication, we're going to explain how we compute it using equations. Previously, we took the dot product of our first weight matrix row and the input vector. This time, we're going to take the dot product of our second weight matrix row and the input vector.

In our visual, we'll start by calculating the first row dot product, then the second row dot product, and finally, we'll add them up.

So we'll plug in values for each weight. We'll use different weights from before, using 3 instead of 0.75 for ear to nap. As we convert from input to output, notice which weights on the bottom left matrix light up. 

First, we'll convert our nose vector into nap space using the weight 2 nap over nose. What this weight does is map the nose basis vector to nap space. This is because x1, our input value, scales our nose vector the same amount in both spaces.

Now we'll do the same for converting our ear vector into nap space.

For our input values, we'll use one for both x1 and x2, and scale the basis vectors by them in both spaces.

Finally, we'll add our nose and ear vectors together in both spaces.

Next, let's do the same thing, but for luck space. We'll convert our nose vector into luck space, 

and then our ear vector into luck space.

At last, we have our nap and luck values, so we'll just combine them.

Now, there's another way you can obtain the same output. We're going to re-arrange our equations so that instead of doing the dot product row by row, we're going to first convert the nose basis vector into nap and luck space, then convert the ear basis vector into nap and luck space.

As we re-arrange this equation, you can pause at each step if you want to take a better look at it.

First, let's use the distributive property to break our input into the nose basis vector and ear basis vector. Next, we'll factor out the input values.

Now we'll take the dot product for each term, by applying the same formula at the top.

Simplifying, we get this expression at the bottom, which is actually just adding the nose vector transformed into nap and luck space, and the ear vector transformed into nap and luck space.

Note that this is actually what we've been doing before on the left side, the Input Space. For our input space, we use these weight values, which make up the identity matrix, as after it multiplies with a vector, it just returns the same vector, just like multiplying by 1.

This is clear when we look at it visually. First, we transform our nose vector into nap and luck space, which we've also been calling the output space.

Notice that the nose vector is seen from two different perspectives: the nap dimension sees it from its frame of reference, and the luck dimension interprets it from its point of view. We add these two interpretations of nose vector together to get the nose vector within the output space.

Then we transform the ear vector into nap and luck space using the same procedure.

Finally, we add together the nose and ear vectors in both input space, and output space. We see that we get to the same point as before. Not only did we transform the nose and ear vectors into output space, but because Tom, at [1,1] in Input Space, was calculated using nose and ear vectors, Tom is also transformed into output space. This says that Tom has a nap smile of 5, and a luck value of -1, which means he's a bit unlucky.