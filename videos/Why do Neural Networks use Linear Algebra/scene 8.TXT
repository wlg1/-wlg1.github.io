SCENE 8:

[
first add in weights of new row, then transform that NN into new space. ? becomes Luckiness. rotate and fade out.

left: crop offset x 0.4; y -0.4
right: crop offset x 0.4

scalars start as x1, x2 then transform to values

8.1. show w11 + w12, then w21 and w22. matrix in b/w
    1. vid 1 transform x vec into right out of bounds, moving in from left out of bounds on vid 2 (w11)
    2. transform y vec into a horizontal (w12)
    3. w11 + w12
    4-6. repeat for w21 and w22
    
ii. then AT SAME TIME (w11, w21; then w12 and w22)
    [w11+w12, 0] + [0, w21+w22]
    when w11 and w21, moves to 2D, and that scales

    notice it was faded before. faded means it's not actually there

    on left side, just show red basis first, and move to right. then show blue
in all 3 cases, add left side at end

arrange: top left is Input, bottom left is matrix. left goes down, then goes to top right. right is transformed. have thin black slice separated input vs right

]

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
The first row in our weight matrix calculates one output value. Adding a second row calculate another output value. This neural network can be mapped to a unit conversion visual. Before, our first output was Nap Smile. Let's calculate a second output called Luck, which measures how lucky a cat person is.

If we rotate ear and luck to be vertical, we are mapping from one 2D coordinate space to another 2D coordinate space. The values in Input Space on the left will go through the matrix at the bottom left to be converted into our Output Space on the right.

<<<
Now before we get into the visual matrix multiplication, we're going to explain how we compute it using equations. Previously, we took the dot product of our first weight matrix row and the input vector. Now, we're going to take the dot product of our second weight matrix row and the input vector.

<<<
In our visual, we'll start by calculating the first row dot product, then the second row dot product, and finally, we'll add them up.

So we'll plug in values for each weight. We'll use different weights from before, using 3 instead of 0.75 for ear to nose. As we convert from input to output, notice which weights on bottom left matrix light up. 

First, we'll convert our nose vector into nap space using the weight 2 nap over nose. What this weight does it map the nose basis vector to nap space. This is because x1, our input value, scales our nose vector the same amount in both spaces.

Now we'll do the same for converting our ear vector into nap space.

For out input values, we'll use one for both x1 and x2, and scale the basis vectors by them in both spaces.

Finally, we'll add our nose and ear vectors together in both spaces.

<<<
Next, let's do the same thing, but for luck space. We'll convert our nose vector into luck space, 

and then our ear vector into luck space.

At last, we have our nap and luck values, so we'll just combine them.

<<<
Now, there's another way you can obtain the same output. We're going to re-arrange our equations so that instead of doing the dot product row by row, we're going to first convert the nose basis vector into nap and luck space, then convert the ear basis vector into nap and luck space.

As we re-arrange this equation, you can pause at each step if you want to take a better look at it.

First, let's use the distributive property to break our input into the nose basis vector and ear basis vector. Next, we'll factor out the input values.

Now we'll take the dot product for each term, by applying the same formula at the top.

Simplifying, we get this expression at the bottom, which is actually just adding the nose vector transformed into nap and luck space, and the ear vector transformed into nap and luck space.
    at end, transform colors into light red and light blue, and pause for 3 seconds.

Note that this is actually what we've were doing before on the left side, the Input Space. For our input space, we use these weight values, which make up the identity matrix, as after it multiplies with a vector, it just returns the same vector, just like multiplying by 1.

<<<
This is clear when we look at it visually. First, we transform our nose vector into nap and luck space, which we've also been calling the output space.

Notice that the nose vector is seen from two different perspectives: the nap dimension sees it from its frame of reference, and the luck dimension interprets it from its point of view. We add these two interpretations of nose vector together to get the nose vector within the output space.

Then we transform the ear vector into nap and luck space using the same procedure.

Finally, we add together the nose and ear vectors in both input space, and output space. We see that we get to the same point as before. Not only did we transform the nose and ear vectors into output space, but because Tom, at [1,1] in Input Space, was calculated using nose and ear vectors, Tom is also transformed into output space. This says that Tom has a nap smile of 5, and a luck value of -1, which means he's a bit unlucky.
    pause for at least 3 seconds after finishing