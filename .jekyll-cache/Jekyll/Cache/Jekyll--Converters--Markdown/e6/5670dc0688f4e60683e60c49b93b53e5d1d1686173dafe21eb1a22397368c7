I"È4<p><strong>CHAPTER 1.1</strong></p>

<p><a href="index.md">back</a></p>

<p>Let‚Äôs start with an example that will show us how matrix multiplication transforms data to reveal new insights. Say there‚Äôs a population of cats and rats, and we represent them in a dataset. However, the dataset is only able to measure two features: body size, and face length (or more specifically, snout length).</p>

<p><img src="/cob/fig1.PNG" alt="Figure 1: Cat" /></p>

<p>So every entity in the population is represented in the dataset as a data point, which is an abstraction defined only by body size and face length. We can represent the data points in this dataset as points in a coordinate space, using the two features as axes. As shown in the bottom row of this Figure, data point corresponds to an image:</p>

<p><img src="/cob/fig2.PNG" alt="Figure 2" />
<img src="/cob/fig3.PNG" alt="Figure 3" />
<!---Make dataset image: first row is face, second row is body, third row is data pt (combo of both) using #s, then show in coord sys on right. Then in 2nd image, turn all numbers into imgs, and again show in coordsys on right.---></p>

<p>When labeling our coordinate space, if we use only the images of unit 1, we get:
<img src="/cob/fig4.PNG" alt="Figure 4" /></p>

<p>Every data point is a combination of <img src="/cob/face1.PNG" width="50" height="40" /> and <img src="/cob/body1.PNG" width="50" height="40" />. For instance, the data point (2, 0.5), which represents [cat pic], is a weighted combination of 0.5 * <img src="/cob/face1.PNG" width="50" height="40" /> and 2* <img src="/cob/body1.PNG" width="50" height="40" /></p>

<p><img src="/cob/fig5.PNG" alt="Figure 5: Linear Combination" /></p>

<p>If we see each data point as a vector, then every vector is an addition of <img src="/cob/face1.PNG" width="50" height="40" /> and <img src="/cob/body1.PNG" width="50" height="40" />, such that <img src="/cob/face1.PNG" width="50" height="40" /> and <img src="/cob/body1.PNG" width="50" height="40" /> are basis vectors. And so in this coordinate space, every entity like [cat pic] is labeled using an addition of <img src="/cob/face1.PNG" width="50" height="40" /> and <img src="/cob/body1.PNG" width="50" height="40" />. Thus (2, 0.5) can also be represented as [2 0.5] = [basis vector addition]</p>

<script type="text/javascript" charset="utf-8" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,
https://vincenttam.github.io/javascripts/MathJaxLocal.js"></script>

<p>\(a^2 + b^2 = c^2\) ‚Äì&gt; note that all equations between these tags will not need escaping!</p>

<p><img src="/cob/fig6.PNG" alt="Figure 6: Cat in Coordinate Space" />
<!---
[under each body size pic, number it so reader knows if it's 1, 2, etc. The 2 glues two 1s together, showing the border, the 0.5 shows the other half grayed out, etc. This is to indicate they're scaling the unit vector. But [cat pic] does not do this, since it's not always measured using bodysize or face length, it's just pure data that can be represented using different features. you can show the addition with an 'intermediate step' that shows gluing them on, then removing the borders/faded. can also be gif]---></p>

<p>Now there is another way to measure the entities in this population. We can assign each entity the following two labels:</p>

<p>1) How likely it is to be a cat</p>

<p>2) How likely it is to be a rat</p>

<p>How do we find the values of these new measurements? We can calculate them using the measurements from the previous system. For example:</p>

<p>Shorter face + Bigger body = Cat</p>

<p>Longer face + Smaller body = Rat</p>

<p>Or in terms of basis vector addition:</p>

<p>Fig 7
[figure showing the analogy: 
Bigger body + Shorter face = Cat
2 * [body pic X] + 0.5 * [face pic Y] = value 2X+0.5Y on cat axes ]</p>

<p>What are X and Y? These are how much each feature is weighted by to calculate the score of ‚Äúlikely to be cat‚Äù. The higher the weight, the more that feature is taken into account for during calculation. We will reveal how these weights are related to the matrix once we get into the algebra of matrix multiplication in section [].</p>

<p>[coordinate space of body size vs face length, showing cat and rat, but onto it fades ‚Äòlikely a cat‚Äô and ‚Äòlikely a rat‚Äô. then it shifts.]</p>

<p>This second measurement forms a second coordinate space. Since each coordinate space is a different way to represent the data, let‚Äôs call each coordinate space a Model. The first model we saw will be Model 1, and the second will be Model 2. Since these two measurement methods are measuring the same entities, the entities in Model 1 are present in Model 2, but are labeled differently:
<!---
[coordinate space and labeled vectors don't change, and there's only 1. Only objs prev on basis vectors move.]
[as it's changing, the old basis labels shift too. the word 'body size' shifts into a non-axes vector, but the word 'likely a cat' shifts onto the basis vector. all 4 axes concepts are present.]
[ Another way to fade is to first show images, then fade away into colored dots, then move dots, and fade images back in.]
https://docs.manim.community/en/stable/reference/manim.animation.fading.FadeOut.html
Or fade out still image using video editor---></p>

<p><img src="/cob/fig8.PNG" alt="Figure 8" /></p>

<p>(Likely a cat 1 (axis j) means ‚Äú1 unit sure‚Äù? Use pic of actual cat with ‚Äòlikely‚Äô over it?)</p>

<p>The <img src="/cob/face1.PNG" width="50" height="40" /> that c (colored) pointed to is now in a new location in Model 2. So is the <img src="/cob/body1.PNG" width="50" height="40" /> that d pointed to.*</p>

<ul>
  <li>note that [body size 1] is present in Model 2, even though it‚Äôs missing [face length]. In other words, it‚Äôs [body size 1] + 0 * [face length 1]. This means that any data point which only contains a body of size 1 is seen as [meaning in terms of basis jk]</li>
</ul>

<p>Fig 9a,9b
[Model 1, and Model 1 on top of Model 2. Sys 2 ‚Äòjk‚Äô. WITH vectors.]
Disclaimer: now show with rotated vectors. Animation doesn‚Äôt rotate vectors. This can get confusing because before, the vectors stayed in place. So we have to note that these are different vectors, just colored the same way because they point onto the same data point.
To prev clutter here, ONLY use 2 vectors: c and d. Or perhaps don‚Äôt show them as vectors, just as dots. This should be clean and summarized.</p>

<p>We know in Model 1 that [2 0.5] is [cat pic].</p>

<p><img src="/cob/fig10.PNG" alt="Figure 10" />
<!---
<img src="/cob/fig10a.png" width="300" height="200">
<img src="/cob/fig10b.png" width="300" height="200">
---></p>

<p>[[2 0.5] catpic in Model 1 and [2 0.5] in Model 1 on 2. I vector is fixed. unlike prev anim, fade j,k only after change basis so not too cluttered]</p>

<p>The two [2 0.5] no longer label the same Concept! [labels cat pic on left, and nothing on right] [color code or include pic of vector when referring to [2 0.5] in text paragraph]</p>

<p>This is because [2 0.5] no longer has the same meaning as it did in Model 1. Now it means ‚Äúit‚Äôs very likely to be a rat (2), but not as likely to be a cat (0.5)‚Äù. In fact, [2 0.5] should now point to [rat pic], instead of [cat pic].</p>

<p>Fig 11
[now fill in what [2 0.5] is in Sys 2]</p>

<p>This shows the difference between the entities in the real world, and the model that represents those entities using labels. [2 0.5] is not [cat pic] itself; it is merely a label of it, and whichever label is used for [cat pic] depends on the basis vectors used to define every label.</p>

<p>[2 0.5] != [cat pic]</p>

<p>Fig 12
[animated reality of concepts vs fixed coord space model]</p>

<p>Notice that Model 2 demonstrates an idealized, simplified example of what a neural network does- it is making a guess about the data point given to it as input. In fact, one can think of it as a single layer ‚Äòneural network‚Äô such that for its neuron function:</p>

<p>o = ReLU(WX + b)</p>

<p>used to calculate the values it guesses for the 2 classes {cat, rat}, it sets ReLU = identity and b = 0, thus using the equation:</p>

<p>o = WX</p>

<p>Fig 13
[picture of X as input vector, W as arrow, O=WX as Model 2 vector on [cat pic]]</p>

<p>While [cat pic] is merely how the dataset sees [actual cat pic], we are referring to [cat pic] as an ‚Äúentity in the real world‚Äù. This is because the only information the neural network knows about [actual cat pic] comes from [cat pic]. For the purposes of this example, we can replace [cat pic] with [actual cat pic] to explain the same concept.*</p>

<p>Fig 14
[fading gif of changing abstractions back to actual pics; place images on coord sys]</p>

<p>? * FOOTNOTE: In this example, [cat pic] contains information from the original dataset that does not change after the transformation- namely, body size and face length. However, in other cases, it is possible for a transformation to reduce the information previously contained, although this information may not be important.</p>

<hr />

<p>Let‚Äôs look at another example involving [poison pic and gift pic] to further illustrate the difference between the real world and our coordinate space model. Instead of using numbers, let‚Äôs use letters to label our entities.</p>

<p>[first show coordinate space labeling gift as poison]</p>

<p>To an English speaker, this may look wrong. But in German, [poison pic] is in fact called ‚Äògift‚Äô. If a German speaker tells the English speaker that they‚Äôre giving the English speaker a gift, the English speaker may be delighted. But they shouldn‚Äôt be, because what they‚Äôre actually receiving is [poison pic], which would kill them.</p>

<p>Instead, the English speaker needs to know what [poison pic] is actually referring to. So they need to translate from German to English as follows:</p>

<p>[animation transforming poison and gift pics to English coordinate space. The vector does not move. Label first Sys as German, second as English.]
[Don‚Äôt give names to basis vectors, ONLY show I -&gt; gift, which is wrong.]</p>

<p>label (‚Äògift‚Äô) in German != label (‚Äògift‚Äô) in English
label (‚Äògift‚Äô) in German ~ label (‚Äòpoison‚Äô) in English</p>

<p>Relating this back to using numbers as labels (write #s below):
label [2 0.5] (‚Äògift‚Äô) in German != label [2 0.5] (‚Äògift‚Äô) in English
label [2 0.5] (‚Äògift‚Äô) in German ~ label [? ?] (‚Äòpoison‚Äô) in English</p>

<p>Now if the English speaker tells the German speaker that they‚Äôre giving them a ‚Äògift‚Äô, the German speaker must translate this to a German translation* that makes them understand that it‚Äôs [gift pic].</p>
<ul>
  <li>not necessarily a word, but possibly a German sentence, or even a paragraph or textbook</li>
</ul>

<p>[show coordinate space w/ Geschenk]</p>

<p>[2 0.5] (Gift, German) != [2 0.5] (Gift, English)
[2 0.5] (Gift, German) ~= [-4 1] (Disgust, English)
[1/3 5/3] (Geschenk, German) ~= [2 0.5] (Gift, English)</p>

<p>Note that there is a difference between ‚Äúwhat gift translates to‚Äù and ‚Äúwhat gift means‚Äù. ‚ÄúWhat gift translates to in German‚Äù means what the label on [gift pic] is in English. ‚ÄúWhat gift means in German‚Äù is about what the LABEL ‚Äògift‚Äô itself points to in German. The entity [gift pic] and the label ‚Äògift‚Äô are not the same. They are only the same when using English, which is defined by the ‚ÄúEnglish basis vectors‚Äù. More about what this means will be discussed in section X, which views basis vectors in a similar way to the Rosetta Stone.</p>

<p>‚Äúwhat gift translates to‚Äù : [gift pic]
‚Äúwhat gift means‚Äù: the label ‚Äògift‚Äô (each label should be highlighted w/ diff font)</p>

<p>But what does the label ‚Äòdisgust‚Äô mean in German? As we see in the German coordinate space, it does not point to any entity. In fact, the label ‚Äòdisgust‚Äô does not mean anything in German. Not all labels have to point to an entity; so in some coordinate spaces, they just mean nonsense. This is an instance of ‚Äònot confusing the map for the territory‚Äô- the map of Switzerland is not 1-1 with Switzerland itself. The model may not capture everything about reality.</p>

<p>[show a place in Switzerland not on the map]</p>

<ul>
  <li>this is an example of a False Friend. link</li>
</ul>

<p>¬´&lt;
Now that we understand the difference between entities and labels, let‚Äôs look back at our example with cats and rats. Remember that in Model 2, the vector I no longer labels the entity [cat pic]; in Model 2, it‚Äôs the vector O that labels [cat pic].</p>

<p>[put vector O on coord sys]</p>

<p>How do we calculate what the new label for [cat] is? As we‚Äôll soon see in section X, the answer is found using Matrix-Vector Multiplication.</p>

<p>¬´&lt;
MOVE TO 1.1+:
Note that the relationships between the entities doesn‚Äôt change. Since the basis vectors from Model 1 still exist in Model 2, you can still use the instructions from Model 1, but you have to translate them using the change of basis matrix.
‚Ä¶ As we‚Äôll see in section X, this is why the dot product instructions work.</p>

<p>section Y will delve deeper into the relationships between concepts, and how they can be preserved or destroyed via matrix multiplication. It retrieves insights that are crucial for‚Ä¶</p>

<p>While [cat pic entity] is a representation of a entity that exists in the real world, 
Relationships are preserved. Analogy. Structure preserving map
[Maps between 2 domains: the real world, and the coordinate space]</p>

:ET