# Links to Fellowship Shared Files

[https://drive.google.com/drive/folders/1ZOg8Nw1L1EPprlK1I32wIPmKnFWz6IGB](https://drive.google.com/drive/folders/1ZOg8Nw1L1EPprlK1I32wIPmKnFWz6IGB)

researchers shared drives

[Messages](Links%20to%20Fellowship%20Shared%20Files%207210eabe5bac45a0adee1dd6f1d92cd9/Messages%204864980156af45d5bddeafa3e027a939.md)

---

[https://www.alignmentforum.org/posts/pH6tyhEnngqWAXi9i/eis-xiii-reflections-on-anthropic-s-sae-research-circa-may](https://www.alignmentforum.org/posts/pH6tyhEnngqWAXi9i/eis-xiii-reflections-on-anthropic-s-sae-research-circa-may)

victor veisch (linear repr hypothesis)

- sparse features removal
    
    (A) Removing interpretable but irrelevant features improves performance,
    (B) Keeping only interpretable and relevant features for steering drastically worsens performance,
    
    Doing some set operations, does this mean that it is the set of uninterpretable features that make it work?
    Total features = Uninterpretable + Interpretable(relevant) + Interpretable(irrelevant)
    
    all < interpretable(relevant) + uninterpretable >> interpretable(relevant)
    

teaching clip to 10; is bad at counting

image and text frozen, but bridge Adapter in between is trained, and still find neurons correspond to text concepts (bau)

text-vision end to end is expensive, vision is relevant bc cheaper. is there circuit from text to vision?

sae may fail to find true features. composed, but may try get features in more irreducible. vae men women glasses; train on 3/4 and it can gen to 4th. composability is good to prevent a neuron specific for men glasses and women glasses etc (combos). regualizre repr to be similar.

[https://arxiv.org/abs/1711.00066](https://arxiv.org/abs/1711.00066)

icloud compute a few thousand

they needed uninterpretable for some reason

[https://arxiv.org/pdf/2311.12786](https://arxiv.org/pdf/2311.12786)
fine tune MI