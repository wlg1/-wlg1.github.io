# Analogous Reasoning

Analogous reasoning: finds missing structure and infers from it, just like knowing the first ind of tensor is batch, so we can understand thatâ€™s batch too. This structure must be represented somewhere. Especially for induction. How does it remember a pattern? 

Steer by feature relations of distance or causal. This is true steering by concepts. Concepts are captured by a network of features, not a single feature. A bridge vs golden gate Bridge. In that case, it's not saes. 

Kernel is distance between samples, not features

Structure preserving feature relations

Feature must be at some threshold 

Sim measure within model between hierarchical analogous concepts

measure common subspace

Relation in terms of containment, and replacement mapping, not just distance. Locked in to map multiple chains of connecting relns

Trace backwards single token inputs or two contrasting differing by single input. Measure the feature dim for traits along each. Do this for both neurons, sae features, components. Then measure distances between these features. Is there a pattern?

Ask gpt4 to critique and refine this