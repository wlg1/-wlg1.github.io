# Feature Geometry- Lit Review

https://arxiv.org/abs/2405.07987

[https://twitter.com/phillip_isola/status/1790488966308769951](https://twitter.com/phillip_isola/status/1790488966308769951)

https://github.com/minyoungg/platonic-rep

- remarks
    
    What they actually show is that 1) affine maps do a pretty good job of translating between the representation spaces of different NNs across, and 2) as models get stronger, they tend to have representation spaces that align more closely with each other. There are a lot of other hypothesis that explain these results so I think they jump the gun a little by dedicating >half the paper to analysis
    
    1. One could be that neural networks are predisposed to learning spaces that can easily be mapped between with affine transformations. Another is that we might see a plateau in representation alignment once the models have eaten up all the low-hanging fruit on lossless abstractions
    2. ***May 16, 2024 4:21 PM (EDT)*May 16, 2024 4:21 PM (EDT)*May 16, 2024 4:21 PM (EDT)***
        
        One thing to consider in their graphs that plot models on axes of language capability vs alignment with vision models is that it seems linear but if you switch out the language capabilities with the compute cost of training, you'll see what might end up being an asymptote
        

https://www.reddit.com/r/MachineLearning/s/ElJYeGM9JX

---

[https://www.alignmentforum.org/posts/bchjSwxBTxZBFXBXs/the-local-interaction-basis-identifying-computationally](https://www.alignmentforum.org/posts/bchjSwxBTxZBFXBXs/the-local-interaction-basis-identifying-computationally)

[https://www.alignmentforum.org/posts/MFBTjb2qf3ziWmzz6/sae-feature-geometry-is-outside-the-superposition-hypothesis](https://www.alignmentforum.org/posts/MFBTjb2qf3ziWmzz6/sae-feature-geometry-is-outside-the-superposition-hypothesis)

UMAP:

- [https://transformer-circuits.pub/2023/monosemantic-features](https://transformer-circuits.pub/2023/monosemantic-features)
    
    ![Untitled](Feature%20Geometry-%20Lit%20Review%20384f2f70a32245a7a9aa5b1481cd85ab/Untitled.png)
    
    Do they take mean activations?
    
    ![Untitled](Feature%20Geometry-%20Lit%20Review%20384f2f70a32245a7a9aa5b1481cd85ab/Untitled%201.png)
    

[https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)

---

[https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uE-CihIAAAAJ&sortby=pubdate&citation_for_view=uE-CihIAAAAJ:t6usbXjVLHcC](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uE-CihIAAAAJ&sortby=pubdate&citation_for_view=uE-CihIAAAAJ:t6usbXjVLHcC)

https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uE-CihIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uE-CihIAAAAJ:XiSMed-E-HIC

[https://arxiv.org/pdf/2302.07384](https://arxiv.org/pdf/2302.07384)

The Geometry of Neural Netsâ€™ Parameter Spaces Under Reparametrization