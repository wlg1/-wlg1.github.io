# Networking

- Feb 24th MI #general post
    
    Just got back to looking at the sleeper agents paper from the reading group a few weeks ago, I was wondering if anyone has tried replicating it yet for non-Anthropic models as per this post: [https://www.alignmentforum.org/posts/M8kpzm42uHytnyYyP/how-to-train-your-own-sleeper-agents](https://www.alignmentforum.org/posts/M8kpzm42uHytnyYyP/how-to-train-your-own-sleeper-agents)
    I assume the backdoored Anthropic models are not available to the public
    
- Alice Rigg DM
    
    Hi, I was interested in your talk about the future direction of MI, and was wondering about how the research in interpreting the effects of fine tuning are going. I saw in the server that there are papers in that area (Fine-Tuning Enhances Existing Mechanisms, [https://openreview.net/forum?id=8sKcAWOf2D](https://openreview.net/forum?id=8sKcAWOf2D) and Editing Models with Task Arithmetic), and I was wondering what you think about pursuing a direction that studies and compares the internals of different fine tuning approaches? Do you know of any other research in this area, and is it feasible/fruitful at this time? Thanks!
    
    I think in the paper, "ok-enough" sleeper agenty properties emerge at the ~10b parameter scale that are robust to RL or SFT approaches, and don't just immediately collapse
    i think this could definitely be an eleuther-backed project, if you got enough momentum going for it
    
    ah, i see. in general, i was looking to study models related to deceptive behavior, trying to find some i can study without a lot of compute
    makes sense, was looking to start small scale first for prelim expms
    

Emails

[email- why algtop needed](Networking%205eb6990dfeee475b920112de369de0ab/email-%20why%20algtop%20needed%2090a8057d0f47426f848c74b01f797949.md)