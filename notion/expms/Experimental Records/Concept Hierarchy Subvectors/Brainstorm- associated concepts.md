# Brainstorm- associated concepts

Associated Concepts Network Brainstorm

There are patterns among the concepts. Not just find the circuit; there is a PATTERN for each concept, that is analogous across models. This is what interpretability is missing. No one will uncover this but you. It is a new paradigm.

- a new method to look at activation differences, similar to activation steering, of related concepts to try to find a relational network of analogous representations at diff layers across models
    
    ask callum about issues with this approach
    
- Concepts related to bad vs good. Can it make stereotypes by these associations? How do they change across layers- are there layers where it decides this?
- If it knows X is related to Y, and Y_2 is a type of Y, it should know X is related to Y_2. How is this reasoning performed within the model?

Youâ€™re still in project planning stage. If idea is so novel, then work by yourself. If not that novel, recruit people. Actually you can do both at the same time.