# Source

![Untitled](Source%2087dbcdcfe1d646728d0052a1cde2aa60/Untitled.png)

**********************************************This should be searchable and builds/unfurls ‘on the fly’ (lazy), calculated by an AI, using axioms and statements you input in. The algorithms can also question where each part of your statement was from, and how reliable that source is. Mix both ‘on the fly’ (like haskell) and ‘stored’ (like databases).**********************************************

*Different logic system programs give different results. They will auto calculate w/ suggestions, and you can alter them. Then Source will store multiple perspectives: yours, the multiple AIs, etc. Look for existing tools.*

DISCLAIMERS: This is not comprehensive, and also not fully reliable. It is merely a tool to help your mind organize and double check thoughts that are hard to keep track of and calculate with each other. It can also suggest what to question, and you can argue with it.

Do not fear or stress out about knowing everything. That’s why there are multiple people- to divide and conquer, and work with each other. Only focus on small steps ahead of you right now.

The scope of this in-development tool won’t cover controversial topics because it will quickly get shut down. It’s not a 100% reliable tool so it should not be used for any big, important decisions or opinions- mainly use it to reason about neutral topics, such as math, chemistry or physics calculations. Those topics are involve a lot of room for misinterpretations. Don’t associate it with those topics.

---

PROOF OF CONCEPT EXAMPLES

The sky is blue.

AI will now suggest similar questions for you to fill in. You get rewarded as you fill in more things, as they fill in “missing values”. More filled-in = more rewards? This may backfire if use reward hacking.

Trains can break.

SOURCES: 

- I saw news reports from Yahoo
    
    Yahoo reliability: ???
    
- I was told about it.
    - I don’t remember, but I FEEL it’s certain.
        - Feelings are not discounted, but are hard to communicate and agreed upon by others. It is hard for others to believe.
        - Subjective weighing of feeling: B/w “I remember that lyrics from that kid’s show I saw 10 years ago” and “I remember seeing a bird fly before”
            - This is calibrated with help of AI’s suggestions, to try to reduce the bounds range

Vitamin C is good for you.

SOURCES: 

- My doctor said so
    - My doctor reliability:
        - They were right about most things
            - (Algo highlights) Unclear: What is “most”?
                - You can choose to stay in this uncertainty as an assumption b/c fairly confident, or question it further
        - Many people trust them
- Many doctors say so
    - If you google it, you’ll find many of the top results saying so
        - UNCLEAR: Google at what time?
        - Google Reliability (links to huge public page and calculations about Google’s history- ongoing debate b/w users)
            - On cloned Google page (updates with main fork): I agree with that, or I doubt that. You decide.

Use the addition rule to calculate mutually exclusive event probabilities.

SOURCE: [https://www.khanacademy.org/math/statistics-probability/probability-library](https://www.khanacademy.org/math/statistics-probability/probability-library)

---

FEATURES:

The AI can point out contradictions. Like spell check, it’s not always right. You can ‘disagree’ with it and argue with the AI. It can also argue back if your argument isn’t good enough. This AI is NOT just an “autocomplete LLM”; it is built with algorithmic logic checkers too.

What checks and tests does it pass? Community can discuss the effectiveness of tests, and suggest their own.