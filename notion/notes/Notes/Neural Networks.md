# Neural Networks

[Interpretability](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Interpretability%20f36507ee13ac4e3996063b9939b8d062.md)

[Safety](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Safety%2060305a19573646b28e22266f48559f60.md)

---

[Transformers](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Transformers%2003e1e4e7e9654bd199395f7c72a88571.md) 

[Diffusion Models](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Diffusion%20Models%208b5afb67c0fa472887b2fec0b7f9b0bc.md)

---

[Tensor](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Tensor%205555c4af00994d9fb9a8b7e90d5b18de.md) 

[Low Rank](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Low%20Rank%2080625e8314d84dadb475196257ea6009.md) 

[PCA](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/PCA%2006651e45a22843a29529bcf6b112ceb5.md) 

[Hidden States](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Hidden%20States%20db3887268cff4dbebb92c9f61ad52485.md)

---

[Loss Function](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Loss%20Function%20e75bb14ae1cf419294c3327de8c86c9b.md)

[Gradient Descent](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Gradient%20Descent%20a8cefa967f884b0b9cd07fdcb7b23d96.md) 

[Backprop](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Backprop%20dc6b76a7049f4a58997b84a223dbb659.md) 

[Optimizers](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Optimizers%207ba9e933dc124d89b7c62549e5ea35fe.md) 

[****Batch and Layer Normalization****](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Batch%20and%20Layer%20Normalization%20683d66e7db994beda71b25499d026b48.md)

[Regularization](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Regularization%2012c65aa5e118436fb60a4c8e0b0fde6e.md) 

[Dropout](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Dropout%20a7f554dda7aa43eda6858776d66fd319.md)

---

[Energy Models](Neural%20Networks%20e6abb23474464e098117dced189fb7bb/Energy%20Models%2020dc956a91304bb6abf0b4c0f68252a0.md) 

---

### Research to double check

[https://www.biorxiv.org/content/10.1101/2023.04.11.536352v1](https://www.biorxiv.org/content/10.1101/2023.04.11.536352v1)

****Trained recurrent neural networks develop phase-locked limit cycles in a working memory task****

[https://iopscience.iop.org/article/10.1088/1742-5468/ab11e3/meta](https://iopscience.iop.org/article/10.1088/1742-5468/ab11e3/meta)

**On the number of limit cycles in asymmetric neural networks**