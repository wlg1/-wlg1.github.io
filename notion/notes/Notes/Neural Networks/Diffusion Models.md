# Diffusion Models

[https://learnopencv.com/image-generation-using-diffusion-models/](https://learnopencv.com/image-generation-using-diffusion-models/)

Noise is when particles even out. Reversing noise to structure.

**Forward Diffusion** $q(x_t | x_{t-1})$ **:** The original image (**x0**) is slowly corrupted iteratively (a Markov chain) by adding (scaled Gaussian) noise. No model is involved at this stage.

$x_{t-1} + ε_{t-1} → x_t$

**Backward/Reverse diffusion** $p(x_{t-1} | x_{t})$  : Given a timestep **t** and the noisy image **xt** , predict the noise (έ) added to the image at step **t-1**. 

$x_t  → Model → έ$    ;  $x_{t-1} = x_t - έ$

• Due to the iterative nature of the diffusion process, the training and generation process is generally more stable than GANs (which go from pure noise to image in a single step)

Diffusion Models often use the U-net architecture to predict noise

At each t, how much noise added to an image is controlled by a “variance scheduler”

In the DDPM paper, the authors used a “linear scheduler.” This means that the noise added at each timestep was increased linearly.

Stable Diffusion:

- A text-encoder (like CLIP in Dall-E)
- A U-net to predict noise
- A Variational autoencoder consisting of an encoder and a decoder model.
    - The encoder is used to reduce the image dimensions. The UNet diffusion model works on this smaller dimension.
    - The decoder is then responsible for enhancing/reconstructing the image generated by the diffusion model back to its original size.

- How do markov chains convert one distribution to another using diffusion?
    
    Markov chains can be used to convert one distribution to another using a process called diffusion. Diffusion in Markov chains refers to the spreading or propagation of probabilities or values across states in the chain.
    
    Here's a simplified explanation of how Markov chains accomplish this conversion:
    
    1. Start with an initial distribution: The process begins with an initial probability distribution or set of values assigned to the states of the Markov chain. Each state represents a possible outcome or value.
    2. Transition probabilities: In a Markov chain, transition probabilities determine the likelihood of moving from one state to another in a single step. These probabilities are typically represented by a transition matrix, where each entry represents the probability of transitioning from one state to another.
    3. Iterative updates: To simulate diffusion and transition from one distribution to another, the Markov chain iteratively updates the probabilities or values assigned to each state. In each iteration, the current distribution is multiplied by the transition matrix. This multiplication effectively represents the spreading or diffusion of probabilities or values across the states.
    4. Convergence: Through successive iterations, the distribution gradually converges towards the desired target distribution. The specific dynamics of the Markov chain, including the transition probabilities, influence the speed and accuracy of this convergence.
    
    By adjusting the transition probabilities in the Markov chain, it is possible to control the rate and direction of diffusion. This allows for the transformation of the initial distribution into a different distribution over time.
    
    Diffusion using Markov chains is a powerful technique utilized in various applications, including physics, mathematics, statistics, and machine learning. It enables the modeling and simulation of complex systems and processes where the evolution of probabilities or values follows certain rules or dependencies captured by the Markov chain.
    
- Is the transition matrix learned?
    
    The transition matrix in a Markov chain can be learned or specified depending on the specific application and context.
    
    In some cases, the transition matrix is predefined or specified based on prior knowledge or assumptions about the system being modeled. For example, in simple theoretical examples or well-understood systems, the transition probabilities may be known in advance, and the transition matrix can be directly defined.
    
    However, in many real-world scenarios, the transition matrix is learned from data through various methods. This is particularly true in applications of Markov chains and diffusion processes in fields like machine learning, data analysis, and modeling complex systems.
    
    To learn the transition matrix, one typically relies on observed data or historical information. Various estimation techniques can be used, such as maximum likelihood estimation or Bayesian inference, to estimate the transition probabilities based on the observed transitions between states. These techniques involve analyzing the data and optimizing the parameters of the transition matrix to best fit the observed transitions.
    
    In some cases, the learning process may involve iterative updates, where the transition matrix is refined over multiple iterations to improve its accuracy in capturing the dynamics of the system.
    
    It's important to note that the learning of the transition matrix depends on the availability and quality of the data, as well as the assumptions and modeling choices made during the learning process. The complexity and size of the Markov chain can also impact the feasibility of learning the transition matrix.
    

---

[https://learnopencv.com/denoising-diffusion-probabilistic-models/](https://learnopencv.com/denoising-diffusion-probabilistic-models/)

**Explains the terms of the transition functions (probability density functions) of fwd and bck**

Forward diffusion just gradually adds noise (sampled from Gaussian) to an image, scaled by beta from the variance scheduler

![Untitled](Diffusion%20Models%208b5afb67c0fa472887b2fec0b7f9b0bc/Untitled.png)

Reformulate from beta to alpha terms to go directly from x_0 to x_t without intermediate steps

![Untitled](Diffusion%20Models%208b5afb67c0fa472887b2fec0b7f9b0bc/Untitled%201.png)

samples image $x_t$ from $q(x_t | x_0)$

**How are these image distribution equations used in the code?** It’s used in the loss functions- we need to find the parameters (mean, var) that maximize the likelihood that the output image will belong to the intended image distribution

![Untitled](Diffusion%20Models%208b5afb67c0fa472887b2fec0b7f9b0bc/Untitled%202.png)

Since this is intractable, find ELBO instead

![Untitled](Diffusion%20Models%208b5afb67c0fa472887b2fec0b7f9b0bc/Untitled%203.png)

---

in some systems: if things tend towards entropy, recovering memory is merely a guess of the noise that uncorrupts the more noisy to less noisy?

---

Cross Attention ([REF](Transformers%2003e1e4e7e9654bd199395f7c72a88571/Self-attention%20(QK)%2064a3e43e6ac8491f8a7ddc54a071b903.md))

Stable Diffusion uses cross-attention between the generated image in the U-Net model and the text prompts used for conditioning

![Untitled](Diffusion%20Models%208b5afb67c0fa472887b2fec0b7f9b0bc/Untitled%204.png)