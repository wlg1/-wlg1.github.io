# Safety

[In-context Learning and Induction Heads](../Papers%203fa55c25c0194ccd89e95feefb9e16bc/In-context%20Learning%20and%20Induction%20Heads%20f6c26430e69948fd9168457739f3e173.md) 

> Neural network capabilities — such as multi-digit addition — are known to sometimes abruptly form or change as models train or increase in scale [8, 1], and are of particular concern for safety as they mean that undesired or dangerous behavior could emerge abruptly.
> 

[https://www.redwoodresearch.org/remix](https://www.redwoodresearch.org/remix)

> mature interpretability techniques will let us distinguish between two ML systems that each behave equally helpfully during training – even having exactly the same input/output behavior on the entire training dataset – but where one does so because it is deceiving us and the other does so “for the right reasons.
>